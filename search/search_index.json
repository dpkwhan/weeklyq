{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Mission Statement \u00b6 Learn and practice kdb/q Topics on electronic trading in equities Weekly question Promote collaboration","title":"Home"},{"location":"#mission-statement","text":"Learn and practice kdb/q Topics on electronic trading in equities Weekly question Promote collaboration","title":"Mission Statement"},{"location":"2020/2020.01.06/","text":"Source: adopted from here Introduction \u00b6 Year 2020 is a leap year. The algorithm to determine whether a year is leap year is as follows: Definition of Leap Year Every year that is exactly divisible by four is a leap year, except for years that are exactly divisible by 100, but these centurial years are leap years if they are exactly divisible by 400. For example, the years 1800 and 1900 were not leap years, but the years 2000 and 2020 were. Question \u00b6 Write a function isLeapYear to determine whether a given year is leap year. isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b Answer \u00b6 The following implementation of isLeapYear is borrowed from the official documentation side of Kx Systems. isLeapYear:{mod[;2] sum 0=x mod\\: 4 100 400}; isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b Detailed explanations on above implementation: For any given year x , calculate the remainder of x divided by 4, 100 and 400, respectively. x mod\\: 4 100 400 This gives a boolean to indicate whether the year x is exactly divisible by 4, 100 and 400, respectively. 0=x mod\\: 4 100 400 It shows x is exactly divisible by how many numbers among 4, 100 and 400. The result has a range of 0 to 3. sum 0=x mod\\: 4 100 400 mod[;2] is a function projection, i.e. converting a two-parameter function to a single-parameter function. Let's define s:sum 0=x mod\\: 4 100 400 and s has values from 0 to 3: s=0 : It means that x is exactly divisible by none of 4, 100 and 400. In this case, mod[;2] s is 0. s=1 : It means that x is only exactly divisible by 4. In this case, mod[;2] s is 1. s=2 : It means that x is only exactly divisible by 4 and 100. In this case, mod[;2] s is 0. s=3 : It means that x is exactly divisible by each of 4, 100 and 400. In this case, mod[;2] s is 1. What a clever implementation! Alternatives \u00b6 Use vector operation and function application (the dot) isLeapYear1:{{x;y;z} . 0=x mod\\: 100 400 4}; This implementation is also very efficient but it is more like Python style isLeapYear2:{$[0=x mod 100;0=x mod 400;0=x mod 4]}; Use vector operation and functional evaluation isLeapYear3:{eval enlist[$],0=x mod\\: 100 400 4}; Use logic operator isLeapYear4:{(0=x mod 400)| (0=x mod 4) & (0=x mod 100)}; Performance \u00b6 Use the following command to run each function 100000 times and record the running time: \\t:100000 func each 1800 1900 2000 2020 Function Run Time (ms) isLeapYear1 348 isLeapYear2 390 isLeapYear3 398 isLeapYear4 563 isLeapYear 572","title":"2020.01.06"},{"location":"2020/2020.01.06/#introduction","text":"Year 2020 is a leap year. The algorithm to determine whether a year is leap year is as follows: Definition of Leap Year Every year that is exactly divisible by four is a leap year, except for years that are exactly divisible by 100, but these centurial years are leap years if they are exactly divisible by 400. For example, the years 1800 and 1900 were not leap years, but the years 2000 and 2020 were.","title":"Introduction"},{"location":"2020/2020.01.06/#question","text":"Write a function isLeapYear to determine whether a given year is leap year. isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b","title":"Question"},{"location":"2020/2020.01.06/#answer","text":"The following implementation of isLeapYear is borrowed from the official documentation side of Kx Systems. isLeapYear:{mod[;2] sum 0=x mod\\: 4 100 400}; isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b Detailed explanations on above implementation: For any given year x , calculate the remainder of x divided by 4, 100 and 400, respectively. x mod\\: 4 100 400 This gives a boolean to indicate whether the year x is exactly divisible by 4, 100 and 400, respectively. 0=x mod\\: 4 100 400 It shows x is exactly divisible by how many numbers among 4, 100 and 400. The result has a range of 0 to 3. sum 0=x mod\\: 4 100 400 mod[;2] is a function projection, i.e. converting a two-parameter function to a single-parameter function. Let's define s:sum 0=x mod\\: 4 100 400 and s has values from 0 to 3: s=0 : It means that x is exactly divisible by none of 4, 100 and 400. In this case, mod[;2] s is 0. s=1 : It means that x is only exactly divisible by 4. In this case, mod[;2] s is 1. s=2 : It means that x is only exactly divisible by 4 and 100. In this case, mod[;2] s is 0. s=3 : It means that x is exactly divisible by each of 4, 100 and 400. In this case, mod[;2] s is 1. What a clever implementation!","title":"Answer"},{"location":"2020/2020.01.06/#alternatives","text":"Use vector operation and function application (the dot) isLeapYear1:{{x;y;z} . 0=x mod\\: 100 400 4}; This implementation is also very efficient but it is more like Python style isLeapYear2:{$[0=x mod 100;0=x mod 400;0=x mod 4]}; Use vector operation and functional evaluation isLeapYear3:{eval enlist[$],0=x mod\\: 100 400 4}; Use logic operator isLeapYear4:{(0=x mod 400)| (0=x mod 4) & (0=x mod 100)};","title":"Alternatives"},{"location":"2020/2020.01.06/#performance","text":"Use the following command to run each function 100000 times and record the running time: \\t:100000 func each 1800 1900 2000 2020 Function Run Time (ms) isLeapYear1 348 isLeapYear2 390 isLeapYear3 398 isLeapYear4 563 isLeapYear 572","title":"Performance"},{"location":"2020/2020.01.06a/","text":"Answer \u00b6 The following implementation of isLeapYear is borrowed from the official documentation side of Kx Systems. isLeapYear:{mod[;2] sum 0=x mod\\: 4 100 400}; isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b Detailed explanations on above implementation: For any given year x , calculate the remainder of x divided by 4, 100 and 400, respectively. x mod\\: 4 100 400 This gives a boolean to indicate whether the year x is exactly divisible by 4, 100 and 400, respectively. 0=x mod\\: 4 100 400 It shows x is exactly divisible by how many numbers among 4, 100 and 400. The result has a range of 0 to 3. sum 0=x mod\\: 4 100 400 mod[;2] is a function projection, i.e. converting a two-parameter function to a single-parameter function. Let's define s:sum 0=x mod\\: 4 100 400 and s has values from 0 to 3: s=0 : It means that x is exactly divisible by none of 4, 100 and 400. In this case, mod[;2] s is 0. s=1 : It means that x is only exactly divisible by 4. In this case, mod[;2] s is 1. s=2 : It means that x is only exactly divisible by 4 and 100. In this case, mod[;2] s is 0. s=3 : It means that x is exactly divisible by each of 4, 100 and 400. In this case, mod[;2] s is 1. What a clever implementation! Alternatives \u00b6 Use vector operation and function application (the dot) isLeapYear1:{{x;y;z} . 0=x mod\\: 100 400 4}; This implementation is also very efficient but it is more like Python style isLeapYear2:{$[0=x mod 100;0=x mod 400;0=x mod 4]}; Use vector operation and functional evaluation isLeapYear3:{eval enlist[$],0=x mod\\: 100 400 4}; Use logic operator isLeapYear4:{(0=x mod 400)| (0=x mod 4) & (0=x mod 100)}; Performance \u00b6 Use the following command to run each function 100000 times and record the running time: \\t:100000 func each 1800 1900 2000 2020 Function Run Time (ms) isLeapYear1 348 isLeapYear2 390 isLeapYear3 398 isLeapYear4 563 isLeapYear 572","title":"2020.01.06a"},{"location":"2020/2020.01.06a/#answer","text":"The following implementation of isLeapYear is borrowed from the official documentation side of Kx Systems. isLeapYear:{mod[;2] sum 0=x mod\\: 4 100 400}; isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b Detailed explanations on above implementation: For any given year x , calculate the remainder of x divided by 4, 100 and 400, respectively. x mod\\: 4 100 400 This gives a boolean to indicate whether the year x is exactly divisible by 4, 100 and 400, respectively. 0=x mod\\: 4 100 400 It shows x is exactly divisible by how many numbers among 4, 100 and 400. The result has a range of 0 to 3. sum 0=x mod\\: 4 100 400 mod[;2] is a function projection, i.e. converting a two-parameter function to a single-parameter function. Let's define s:sum 0=x mod\\: 4 100 400 and s has values from 0 to 3: s=0 : It means that x is exactly divisible by none of 4, 100 and 400. In this case, mod[;2] s is 0. s=1 : It means that x is only exactly divisible by 4. In this case, mod[;2] s is 1. s=2 : It means that x is only exactly divisible by 4 and 100. In this case, mod[;2] s is 0. s=3 : It means that x is exactly divisible by each of 4, 100 and 400. In this case, mod[;2] s is 1. What a clever implementation!","title":"Answer"},{"location":"2020/2020.01.06a/#alternatives","text":"Use vector operation and function application (the dot) isLeapYear1:{{x;y;z} . 0=x mod\\: 100 400 4}; This implementation is also very efficient but it is more like Python style isLeapYear2:{$[0=x mod 100;0=x mod 400;0=x mod 4]}; Use vector operation and functional evaluation isLeapYear3:{eval enlist[$],0=x mod\\: 100 400 4}; Use logic operator isLeapYear4:{(0=x mod 400)| (0=x mod 4) & (0=x mod 100)};","title":"Alternatives"},{"location":"2020/2020.01.06a/#performance","text":"Use the following command to run each function 100000 times and record the running time: \\t:100000 func each 1800 1900 2000 2020 Function Run Time (ms) isLeapYear1 348 isLeapYear2 390 isLeapYear3 398 isLeapYear4 563 isLeapYear 572","title":"Performance"},{"location":"2020/2020.01.06q/","text":"Source: adopted from here Introduction \u00b6 Year 2020 is a leap year. The algorithm to determine whether a year is leap year is as follows: Definition of Leap Year Every year that is exactly divisible by four is a leap year, except for years that are exactly divisible by 100, but these centurial years are leap years if they are exactly divisible by 400. For example, the years 1800 and 1900 were not leap years, but the years 2000 and 2020 were. Question \u00b6 Write a function isLeapYear to determine whether a given year is leap year. isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b","title":"2020.01.06q"},{"location":"2020/2020.01.06q/#introduction","text":"Year 2020 is a leap year. The algorithm to determine whether a year is leap year is as follows: Definition of Leap Year Every year that is exactly divisible by four is a leap year, except for years that are exactly divisible by 100, but these centurial years are leap years if they are exactly divisible by 400. For example, the years 1800 and 1900 were not leap years, but the years 2000 and 2020 were.","title":"Introduction"},{"location":"2020/2020.01.06q/#question","text":"Write a function isLeapYear to determine whether a given year is leap year. isLeapYear 1800 / 0b isLeapYear 1900 / 0b isLeapYear 2000 / 1b isLeapYear 2020 / 1b","title":"Question"},{"location":"2020/2020.01.13/","text":"Source: adopted from here Introduction \u00b6 In a standard report on the performance of algo parent orders, the notional weighted average slippage is typically reported. It is fairly simple to calculate weighted average in q using the built-in function wavg . To be consistent, we should also report the notional weighted standard deviation of slippage. Here is the definition of weighted standard deviation . Question \u00b6 The function simSlippage simulates the notional and slippage of 10,000 orders. simSlippage:{ n:10000; system \"S -314159\"; slippage:5-0.01*n?1000; system \"S -314159\"; notional:10000+n?100000; ([] notional:notional;slippage:slippage) }; perfData:simSlippage[]; Write a function in q to calculate the notional weighted standard deviation of these 10,000 orders using the formula provided above. Answer \u00b6 One implementation is suggested as follows. Note the use of inline assignment of variable n and xdm . For curious reader, xdm means \" x d e m eaned\". wsdev:{[w;x] $[1>=n:sum w<>0;:0f;sqrt (n%n-1)*w wavg xdm*xdm:x-w wavg x] }; exec wsdev[notional;slippage] from perfData","title":"2020.01.13"},{"location":"2020/2020.01.13/#introduction","text":"In a standard report on the performance of algo parent orders, the notional weighted average slippage is typically reported. It is fairly simple to calculate weighted average in q using the built-in function wavg . To be consistent, we should also report the notional weighted standard deviation of slippage. Here is the definition of weighted standard deviation .","title":"Introduction"},{"location":"2020/2020.01.13/#question","text":"The function simSlippage simulates the notional and slippage of 10,000 orders. simSlippage:{ n:10000; system \"S -314159\"; slippage:5-0.01*n?1000; system \"S -314159\"; notional:10000+n?100000; ([] notional:notional;slippage:slippage) }; perfData:simSlippage[]; Write a function in q to calculate the notional weighted standard deviation of these 10,000 orders using the formula provided above.","title":"Question"},{"location":"2020/2020.01.13/#answer","text":"One implementation is suggested as follows. Note the use of inline assignment of variable n and xdm . For curious reader, xdm means \" x d e m eaned\". wsdev:{[w;x] $[1>=n:sum w<>0;:0f;sqrt (n%n-1)*w wavg xdm*xdm:x-w wavg x] }; exec wsdev[notional;slippage] from perfData","title":"Answer"},{"location":"2020/2020.01.13a/","text":"Answer \u00b6 One implementation is suggested as follows. Note the use of inline assignment of variable n and xdm . For curious reader, xdm means \" x d e m eaned\". wsdev:{[w;x] $[1>=n:sum w<>0;:0f;sqrt (n%n-1)*w wavg xdm*xdm:x-w wavg x] }; exec wsdev[notional;slippage] from perfData","title":"2020.01.13a"},{"location":"2020/2020.01.13a/#answer","text":"One implementation is suggested as follows. Note the use of inline assignment of variable n and xdm . For curious reader, xdm means \" x d e m eaned\". wsdev:{[w;x] $[1>=n:sum w<>0;:0f;sqrt (n%n-1)*w wavg xdm*xdm:x-w wavg x] }; exec wsdev[notional;slippage] from perfData","title":"Answer"},{"location":"2020/2020.01.13q/","text":"Source: adopted from here Introduction \u00b6 In a standard report on the performance of algo parent orders, the notional weighted average slippage is typically reported. It is fairly simple to calculate weighted average in q using the built-in function wavg . To be consistent, we should also report the notional weighted standard deviation of slippage. Here is the definition of weighted standard deviation . Question \u00b6 The function simSlippage simulates the notional and slippage of 10,000 orders. simSlippage:{ n:10000; system \"S -314159\"; slippage:5-0.01*n?1000; system \"S -314159\"; notional:10000+n?100000; ([] notional:notional;slippage:slippage) }; perfData:simSlippage[]; Write a function in q to calculate the notional weighted standard deviation of these 10,000 orders using the formula provided above.","title":"2020.01.13q"},{"location":"2020/2020.01.13q/#introduction","text":"In a standard report on the performance of algo parent orders, the notional weighted average slippage is typically reported. It is fairly simple to calculate weighted average in q using the built-in function wavg . To be consistent, we should also report the notional weighted standard deviation of slippage. Here is the definition of weighted standard deviation .","title":"Introduction"},{"location":"2020/2020.01.13q/#question","text":"The function simSlippage simulates the notional and slippage of 10,000 orders. simSlippage:{ n:10000; system \"S -314159\"; slippage:5-0.01*n?1000; system \"S -314159\"; notional:10000+n?100000; ([] notional:notional;slippage:slippage) }; perfData:simSlippage[]; Write a function in q to calculate the notional weighted standard deviation of these 10,000 orders using the formula provided above.","title":"Question"},{"location":"2020/2020.01.20/","text":"Source: adopted from here Introduction \u00b6 A set of child orders may be created in each evaluation cycle of a Smart Order Router (SOR) and these orders might be distributed among multiple price levels and even across different trading venues. The code below simulates this order creation process. In each evaluation cycle, five orders are generated, each of which has different price but has the save evaluation id. In this example, there are two parent orders: one for BUY and one for SELL. genCO:{[parentId;waveId;side] n:-5; system \"S -314159\"; ids:`long$.z.N+n?1000; system \"S -314159\"; prices:100+0.01*n?100; system \"S -314159\"; sizes:100*1+n?10; ([] poid:parentId;wid:waveId;coid:ids;side:side;price:prices;size:sizes) }; genOrders:{ buyOrders:raze {poid:`long$22:32:12.163;genCO[poid;x;`BUY]} each 101+til 20; sellOrders:raze {poid:`long$23:32:12.163;genCO[poid;x;`SELL]} each 101+til 20; buyOrders,sellOrders }; orders:genOrders[]; Question \u00b6 Find the most aggressive order, i.e. buy order with the highest price and sell order with the lowest price, within each evaluation cycle. Answer \u00b6 The following two approaches are proposed: Method 1 raze {[s] f:$[s=`BUY;max;min]; select from orders where side=s,price=(f;price) fby ([] poid;wid) } each `BUY`SELL In above implementation: Use raze to merge multiple conforming tables into a single table Conditional selection operator ($) is used to select which function to use based on the order side To group on multiple columns in a fby , tabulate them in group Method 2 { data:`poid`wid`p xasc update p:?[side=`BUY;price;-1*price] from orders; data:delete p from data; 0!select by poid,wid from data }[] A few notes about the second implementation: select by group from table gives you the last row in a group Use 0! on to remove key(s) of a keyed table","title":"2020.01.20"},{"location":"2020/2020.01.20/#introduction","text":"A set of child orders may be created in each evaluation cycle of a Smart Order Router (SOR) and these orders might be distributed among multiple price levels and even across different trading venues. The code below simulates this order creation process. In each evaluation cycle, five orders are generated, each of which has different price but has the save evaluation id. In this example, there are two parent orders: one for BUY and one for SELL. genCO:{[parentId;waveId;side] n:-5; system \"S -314159\"; ids:`long$.z.N+n?1000; system \"S -314159\"; prices:100+0.01*n?100; system \"S -314159\"; sizes:100*1+n?10; ([] poid:parentId;wid:waveId;coid:ids;side:side;price:prices;size:sizes) }; genOrders:{ buyOrders:raze {poid:`long$22:32:12.163;genCO[poid;x;`BUY]} each 101+til 20; sellOrders:raze {poid:`long$23:32:12.163;genCO[poid;x;`SELL]} each 101+til 20; buyOrders,sellOrders }; orders:genOrders[];","title":"Introduction"},{"location":"2020/2020.01.20/#question","text":"Find the most aggressive order, i.e. buy order with the highest price and sell order with the lowest price, within each evaluation cycle.","title":"Question"},{"location":"2020/2020.01.20/#answer","text":"The following two approaches are proposed: Method 1 raze {[s] f:$[s=`BUY;max;min]; select from orders where side=s,price=(f;price) fby ([] poid;wid) } each `BUY`SELL In above implementation: Use raze to merge multiple conforming tables into a single table Conditional selection operator ($) is used to select which function to use based on the order side To group on multiple columns in a fby , tabulate them in group Method 2 { data:`poid`wid`p xasc update p:?[side=`BUY;price;-1*price] from orders; data:delete p from data; 0!select by poid,wid from data }[] A few notes about the second implementation: select by group from table gives you the last row in a group Use 0! on to remove key(s) of a keyed table","title":"Answer"},{"location":"2020/2020.01.20a/","text":"Answer \u00b6 The following two approaches are proposed: Method 1 raze {[s] f:$[s=`BUY;max;min]; select from orders where side=s,price=(f;price) fby ([] poid;wid) } each `BUY`SELL In above implementation: Use raze to merge multiple conforming tables into a single table Conditional selection operator ($) is used to select which function to use based on the order side To group on multiple columns in a fby , tabulate them in group Method 2 { data:`poid`wid`p xasc update p:?[side=`BUY;price;-1*price] from orders; data:delete p from data; 0!select by poid,wid from data }[] A few notes about the second implementation: select by group from table gives you the last row in a group Use 0! on to remove key(s) of a keyed table","title":"2020.01.20a"},{"location":"2020/2020.01.20a/#answer","text":"The following two approaches are proposed: Method 1 raze {[s] f:$[s=`BUY;max;min]; select from orders where side=s,price=(f;price) fby ([] poid;wid) } each `BUY`SELL In above implementation: Use raze to merge multiple conforming tables into a single table Conditional selection operator ($) is used to select which function to use based on the order side To group on multiple columns in a fby , tabulate them in group Method 2 { data:`poid`wid`p xasc update p:?[side=`BUY;price;-1*price] from orders; data:delete p from data; 0!select by poid,wid from data }[] A few notes about the second implementation: select by group from table gives you the last row in a group Use 0! on to remove key(s) of a keyed table","title":"Answer"},{"location":"2020/2020.01.20q/","text":"Source: adopted from here Introduction \u00b6 A set of child orders may be created in each evaluation cycle of a Smart Order Router (SOR) and these orders might be distributed among multiple price levels and even across different trading venues. The code below simulates this order creation process. In each evaluation cycle, five orders are generated, each of which has different price but has the save evaluation id. In this example, there are two parent orders: one for BUY and one for SELL. genCO:{[parentId;waveId;side] n:-5; system \"S -314159\"; ids:`long$.z.N+n?1000; system \"S -314159\"; prices:100+0.01*n?100; system \"S -314159\"; sizes:100*1+n?10; ([] poid:parentId;wid:waveId;coid:ids;side:side;price:prices;size:sizes) }; genOrders:{ buyOrders:raze {poid:`long$22:32:12.163;genCO[poid;x;`BUY]} each 101+til 20; sellOrders:raze {poid:`long$23:32:12.163;genCO[poid;x;`SELL]} each 101+til 20; buyOrders,sellOrders }; orders:genOrders[]; Question \u00b6 Find the most aggressive order, i.e. buy order with the highest price and sell order with the lowest price, within each evaluation cycle.","title":"2020.01.20q"},{"location":"2020/2020.01.20q/#introduction","text":"A set of child orders may be created in each evaluation cycle of a Smart Order Router (SOR) and these orders might be distributed among multiple price levels and even across different trading venues. The code below simulates this order creation process. In each evaluation cycle, five orders are generated, each of which has different price but has the save evaluation id. In this example, there are two parent orders: one for BUY and one for SELL. genCO:{[parentId;waveId;side] n:-5; system \"S -314159\"; ids:`long$.z.N+n?1000; system \"S -314159\"; prices:100+0.01*n?100; system \"S -314159\"; sizes:100*1+n?10; ([] poid:parentId;wid:waveId;coid:ids;side:side;price:prices;size:sizes) }; genOrders:{ buyOrders:raze {poid:`long$22:32:12.163;genCO[poid;x;`BUY]} each 101+til 20; sellOrders:raze {poid:`long$23:32:12.163;genCO[poid;x;`SELL]} each 101+til 20; buyOrders,sellOrders }; orders:genOrders[];","title":"Introduction"},{"location":"2020/2020.01.20q/#question","text":"Find the most aggressive order, i.e. buy order with the highest price and sell order with the lowest price, within each evaluation cycle.","title":"Question"},{"location":"2020/2020.01.27/","text":"Source: adopted from here Introduction \u00b6 NYSE TAQ data provides T+1 trades reported to SIP and each trade has some basic information like timestamp, price, exchange, volume and trade qualifiers. The open/close auction trade on the primary exchange is marked by qualifiers 0 and 6 , respectively. Define the daily volume as the total volume traded between the open/close auction trades on the primary, inclusively. genTrades:{[seed;nTrades] / Randomly generate each trade's timestamp system \"S \",string seed; times:`time$09:28:00.000+nTrades?392*60*1000; / Randomly generate trade size system \"S \",string seed; volumes:`long$100*1+nTrades?10; / Randomly generate each trade's sale condition system \"S \",string seed; saleConditions:{x?`B`C`H`L`N`P`R`T`U`V`X`Z`7`4`5`8} each nTrades?3; / Create a table of trades trades:([] time:times;volume:volumes;saleCondition:saleConditions); / Add the open and close auction trades trades:trades upsert (`time$09:30:00.000+rand 60000;24700j;`O`X); trades:trades upsert (`time$16:00:00.000+rand 2000;53800j;enlist `6); / Sort the trades time by time `time xasc trades }; simTrades:genTrades[-314159;10000]; simTrades Question \u00b6 To simplify the question, it is assumed that open/close auction trades are ALWAYS present. The function genTrades above simulates 10,002 trades. Note that each trade has up to two sale condition codes. Find the total volume between the two auction trades, inclusively. Answer \u00b6 We just need to find the timestamp of the two auction trades and then sum up volume of all trades between these two auction trades. This can be done like: auctionTimes:exec time from simTrades where any each saleCondition like\\: \"*[O6]*\"; select sum volume from simTrades where time within auctionTimes A few notable points worth mentioning: any each saleCondition like\\: \"*[O6]*\" : This where clause identifies the open/close auction trades. exec time from simTrades... : Extract the open and close auction time as a list of two elements. The first element is the time for open auction trade and the second is for close auction trade.","title":"2020.01.27"},{"location":"2020/2020.01.27/#introduction","text":"NYSE TAQ data provides T+1 trades reported to SIP and each trade has some basic information like timestamp, price, exchange, volume and trade qualifiers. The open/close auction trade on the primary exchange is marked by qualifiers 0 and 6 , respectively. Define the daily volume as the total volume traded between the open/close auction trades on the primary, inclusively. genTrades:{[seed;nTrades] / Randomly generate each trade's timestamp system \"S \",string seed; times:`time$09:28:00.000+nTrades?392*60*1000; / Randomly generate trade size system \"S \",string seed; volumes:`long$100*1+nTrades?10; / Randomly generate each trade's sale condition system \"S \",string seed; saleConditions:{x?`B`C`H`L`N`P`R`T`U`V`X`Z`7`4`5`8} each nTrades?3; / Create a table of trades trades:([] time:times;volume:volumes;saleCondition:saleConditions); / Add the open and close auction trades trades:trades upsert (`time$09:30:00.000+rand 60000;24700j;`O`X); trades:trades upsert (`time$16:00:00.000+rand 2000;53800j;enlist `6); / Sort the trades time by time `time xasc trades }; simTrades:genTrades[-314159;10000]; simTrades","title":"Introduction"},{"location":"2020/2020.01.27/#question","text":"To simplify the question, it is assumed that open/close auction trades are ALWAYS present. The function genTrades above simulates 10,002 trades. Note that each trade has up to two sale condition codes. Find the total volume between the two auction trades, inclusively.","title":"Question"},{"location":"2020/2020.01.27/#answer","text":"We just need to find the timestamp of the two auction trades and then sum up volume of all trades between these two auction trades. This can be done like: auctionTimes:exec time from simTrades where any each saleCondition like\\: \"*[O6]*\"; select sum volume from simTrades where time within auctionTimes A few notable points worth mentioning: any each saleCondition like\\: \"*[O6]*\" : This where clause identifies the open/close auction trades. exec time from simTrades... : Extract the open and close auction time as a list of two elements. The first element is the time for open auction trade and the second is for close auction trade.","title":"Answer"},{"location":"2020/2020.01.27a/","text":"Answer \u00b6 We just need to find the timestamp of the two auction trades and then sum up volume of all trades between these two auction trades. This can be done like: auctionTimes:exec time from simTrades where any each saleCondition like\\: \"*[O6]*\"; select sum volume from simTrades where time within auctionTimes A few notable points worth mentioning: any each saleCondition like\\: \"*[O6]*\" : This where clause identifies the open/close auction trades. exec time from simTrades... : Extract the open and close auction time as a list of two elements. The first element is the time for open auction trade and the second is for close auction trade.","title":"2020.01.27a"},{"location":"2020/2020.01.27a/#answer","text":"We just need to find the timestamp of the two auction trades and then sum up volume of all trades between these two auction trades. This can be done like: auctionTimes:exec time from simTrades where any each saleCondition like\\: \"*[O6]*\"; select sum volume from simTrades where time within auctionTimes A few notable points worth mentioning: any each saleCondition like\\: \"*[O6]*\" : This where clause identifies the open/close auction trades. exec time from simTrades... : Extract the open and close auction time as a list of two elements. The first element is the time for open auction trade and the second is for close auction trade.","title":"Answer"},{"location":"2020/2020.01.27q/","text":"Source: adopted from here Introduction \u00b6 NYSE TAQ data provides T+1 trades reported to SIP and each trade has some basic information like timestamp, price, exchange, volume and trade qualifiers. The open/close auction trade on the primary exchange is marked by qualifiers 0 and 6 , respectively. Define the daily volume as the total volume traded between the open/close auction trades on the primary, inclusively. genTrades:{[seed;nTrades] / Randomly generate each trade's timestamp system \"S \",string seed; times:`time$09:28:00.000+nTrades?392*60*1000; / Randomly generate trade size system \"S \",string seed; volumes:`long$100*1+nTrades?10; / Randomly generate each trade's sale condition system \"S \",string seed; saleConditions:{x?`B`C`H`L`N`P`R`T`U`V`X`Z`7`4`5`8} each nTrades?3; / Create a table of trades trades:([] time:times;volume:volumes;saleCondition:saleConditions); / Add the open and close auction trades trades:trades upsert (`time$09:30:00.000+rand 60000;24700j;`O`X); trades:trades upsert (`time$16:00:00.000+rand 2000;53800j;enlist `6); / Sort the trades time by time `time xasc trades }; simTrades:genTrades[-314159;10000]; simTrades Question \u00b6 To simplify the question, it is assumed that open/close auction trades are ALWAYS present. The function genTrades above simulates 10,002 trades. Note that each trade has up to two sale condition codes. Find the total volume between the two auction trades, inclusively.","title":"2020.01.27q"},{"location":"2020/2020.01.27q/#introduction","text":"NYSE TAQ data provides T+1 trades reported to SIP and each trade has some basic information like timestamp, price, exchange, volume and trade qualifiers. The open/close auction trade on the primary exchange is marked by qualifiers 0 and 6 , respectively. Define the daily volume as the total volume traded between the open/close auction trades on the primary, inclusively. genTrades:{[seed;nTrades] / Randomly generate each trade's timestamp system \"S \",string seed; times:`time$09:28:00.000+nTrades?392*60*1000; / Randomly generate trade size system \"S \",string seed; volumes:`long$100*1+nTrades?10; / Randomly generate each trade's sale condition system \"S \",string seed; saleConditions:{x?`B`C`H`L`N`P`R`T`U`V`X`Z`7`4`5`8} each nTrades?3; / Create a table of trades trades:([] time:times;volume:volumes;saleCondition:saleConditions); / Add the open and close auction trades trades:trades upsert (`time$09:30:00.000+rand 60000;24700j;`O`X); trades:trades upsert (`time$16:00:00.000+rand 2000;53800j;enlist `6); / Sort the trades time by time `time xasc trades }; simTrades:genTrades[-314159;10000]; simTrades","title":"Introduction"},{"location":"2020/2020.01.27q/#question","text":"To simplify the question, it is assumed that open/close auction trades are ALWAYS present. The function genTrades above simulates 10,002 trades. Note that each trade has up to two sale condition codes. Find the total volume between the two auction trades, inclusively.","title":"Question"},{"location":"2020/2020.02.03/","text":"Source: adopted from here Introduction \u00b6 One frequently asked question in analyzing the behavior of a Smart Order Router (SOR) is how many time periods in which there is no open child orders on market and what are the start time and length of the no-slice period. The following function genOrders simulates 5,000 child orders with order submission time and the time each order exits from the limit order book. It is assumed that the trading hours is from 09:30 to 16:00 and the parent order arrives exactly at 09:30 . genOrders:{[nOrders;seed;openTime;closeTime] system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exitTimes:closeTime&submitTimes+nOrders?60*1000; ([] orderId:1000+til nOrders;subT:submitTimes;exitT:exitTimes) }; openTime:`time$09:30; closeTime:`time$16:00; simOrders:genOrders[5000;-314159;openTime;closeTime]; Question \u00b6 We want to find all the time periods when there is no open child orders on market and how long each no-order period lasts. The expected output is a table which should look like: startTime periodLength 09:30:00.000 00:00:17.080 10:25:57.802 00:00:04.595 10:29:43.843 00:00:00.676 11:08:07.079 00:00:05.682 12:30:43.199 00:00:08.152 15:29:06.359 00:00:08.213 Answer \u00b6 Below is the suggested answer to this question: times:update maxT:maxs exitT from simOrders; times:update noOrderDur:subT-prev maxT from times; times:update noOrderDur:subT-openTime from times where null noOrderDur; select startTime:`time$subT-noOrderDur,periodLength:`time$noOrderDur from times where noOrderDur>0 Some detailed explanations on the suggested solution: Line 1: Find the running maximum time of order exiting from market. Line 2: Take the difference between the order submission time of each child order and the previous maximum exiting time. There is at least one open order on market if this time difference is negative. Line 3: Determine the period of no orders between market open and the time the first child order is sliced out. Line 4: Select the time period when the length of no-order period is positive.","title":"2020.02.03"},{"location":"2020/2020.02.03/#introduction","text":"One frequently asked question in analyzing the behavior of a Smart Order Router (SOR) is how many time periods in which there is no open child orders on market and what are the start time and length of the no-slice period. The following function genOrders simulates 5,000 child orders with order submission time and the time each order exits from the limit order book. It is assumed that the trading hours is from 09:30 to 16:00 and the parent order arrives exactly at 09:30 . genOrders:{[nOrders;seed;openTime;closeTime] system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exitTimes:closeTime&submitTimes+nOrders?60*1000; ([] orderId:1000+til nOrders;subT:submitTimes;exitT:exitTimes) }; openTime:`time$09:30; closeTime:`time$16:00; simOrders:genOrders[5000;-314159;openTime;closeTime];","title":"Introduction"},{"location":"2020/2020.02.03/#question","text":"We want to find all the time periods when there is no open child orders on market and how long each no-order period lasts. The expected output is a table which should look like: startTime periodLength 09:30:00.000 00:00:17.080 10:25:57.802 00:00:04.595 10:29:43.843 00:00:00.676 11:08:07.079 00:00:05.682 12:30:43.199 00:00:08.152 15:29:06.359 00:00:08.213","title":"Question"},{"location":"2020/2020.02.03/#answer","text":"Below is the suggested answer to this question: times:update maxT:maxs exitT from simOrders; times:update noOrderDur:subT-prev maxT from times; times:update noOrderDur:subT-openTime from times where null noOrderDur; select startTime:`time$subT-noOrderDur,periodLength:`time$noOrderDur from times where noOrderDur>0 Some detailed explanations on the suggested solution: Line 1: Find the running maximum time of order exiting from market. Line 2: Take the difference between the order submission time of each child order and the previous maximum exiting time. There is at least one open order on market if this time difference is negative. Line 3: Determine the period of no orders between market open and the time the first child order is sliced out. Line 4: Select the time period when the length of no-order period is positive.","title":"Answer"},{"location":"2020/2020.02.03a/","text":"Answer \u00b6 Below is the suggested answer to this question: times:update maxT:maxs exitT from simOrders; times:update noOrderDur:subT-prev maxT from times; times:update noOrderDur:subT-openTime from times where null noOrderDur; select startTime:`time$subT-noOrderDur,periodLength:`time$noOrderDur from times where noOrderDur>0 Some detailed explanations on the suggested solution: Line 1: Find the running maximum time of order exiting from market. Line 2: Take the difference between the order submission time of each child order and the previous maximum exiting time. There is at least one open order on market if this time difference is negative. Line 3: Determine the period of no orders between market open and the time the first child order is sliced out. Line 4: Select the time period when the length of no-order period is positive.","title":"2020.02.03a"},{"location":"2020/2020.02.03a/#answer","text":"Below is the suggested answer to this question: times:update maxT:maxs exitT from simOrders; times:update noOrderDur:subT-prev maxT from times; times:update noOrderDur:subT-openTime from times where null noOrderDur; select startTime:`time$subT-noOrderDur,periodLength:`time$noOrderDur from times where noOrderDur>0 Some detailed explanations on the suggested solution: Line 1: Find the running maximum time of order exiting from market. Line 2: Take the difference between the order submission time of each child order and the previous maximum exiting time. There is at least one open order on market if this time difference is negative. Line 3: Determine the period of no orders between market open and the time the first child order is sliced out. Line 4: Select the time period when the length of no-order period is positive.","title":"Answer"},{"location":"2020/2020.02.03q/","text":"Source: adopted from here Introduction \u00b6 One frequently asked question in analyzing the behavior of a Smart Order Router (SOR) is how many time periods in which there is no open child orders on market and what are the start time and length of the no-slice period. The following function genOrders simulates 5,000 child orders with order submission time and the time each order exits from the limit order book. It is assumed that the trading hours is from 09:30 to 16:00 and the parent order arrives exactly at 09:30 . genOrders:{[nOrders;seed;openTime;closeTime] system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exitTimes:closeTime&submitTimes+nOrders?60*1000; ([] orderId:1000+til nOrders;subT:submitTimes;exitT:exitTimes) }; openTime:`time$09:30; closeTime:`time$16:00; simOrders:genOrders[5000;-314159;openTime;closeTime]; Question \u00b6 We want to find all the time periods when there is no open child orders on market and how long each no-order period lasts. The expected output is a table which should look like: startTime periodLength 09:30:00.000 00:00:17.080 10:25:57.802 00:00:04.595 10:29:43.843 00:00:00.676 11:08:07.079 00:00:05.682 12:30:43.199 00:00:08.152 15:29:06.359 00:00:08.213","title":"2020.02.03q"},{"location":"2020/2020.02.03q/#introduction","text":"One frequently asked question in analyzing the behavior of a Smart Order Router (SOR) is how many time periods in which there is no open child orders on market and what are the start time and length of the no-slice period. The following function genOrders simulates 5,000 child orders with order submission time and the time each order exits from the limit order book. It is assumed that the trading hours is from 09:30 to 16:00 and the parent order arrives exactly at 09:30 . genOrders:{[nOrders;seed;openTime;closeTime] system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exitTimes:closeTime&submitTimes+nOrders?60*1000; ([] orderId:1000+til nOrders;subT:submitTimes;exitT:exitTimes) }; openTime:`time$09:30; closeTime:`time$16:00; simOrders:genOrders[5000;-314159;openTime;closeTime];","title":"Introduction"},{"location":"2020/2020.02.03q/#question","text":"We want to find all the time periods when there is no open child orders on market and how long each no-order period lasts. The expected output is a table which should look like: startTime periodLength 09:30:00.000 00:00:17.080 10:25:57.802 00:00:04.595 10:29:43.843 00:00:00.676 11:08:07.079 00:00:05.682 12:30:43.199 00:00:08.152 15:29:06.359 00:00:08.213","title":"Question"},{"location":"2020/2020.02.10/","text":"Source: adopted from here Introduction \u00b6 Let's go one step further by continuing the question from last week. A question asked by algorithmic traders quite often is how many open orders are live on market at any given time. Question \u00b6 Find the time series of the number of open child orders. The question from last week is simply a special case of this question. The output is a table with two columns like below: startTime nOpenOrders 09:30:00.000 0 hh:mm:ss.SSS x hh:mm:ss.SSS y hh:mm:ss.SSS z Answer \u00b6 The child order count should increase by 1 at each order's submission time ( subT ) and decrease by 1 when the order is removed from the market at exit time ( exitT ). Based on this reasoning logic, three tables are created: The first table contains one row, which has order count of zero to accommodate the time period from market open to the time when the first child order is created. The second table contains all new orders. The third table records all orders which are removed from market. Along this line of thinking, the following implementation is suggested: initOrder:([] time:enlist openTime;nOpenOrders:enlist 0); addOrder:select time:subTime,nOpenOrders:1 from simOrders; removeOrder:select time:exitTime,nOpenOrders:-1 from simOrders; orders:select time,sums nOpenOrders from `time xasc initOrder,addOrder,removeOrder; select time,nOpenOrders from orders where differ nOpenOrders The where differ nOpenOrders on the last line above is required to make sure the order count between two consecutive rows are different.","title":"2020.02.10"},{"location":"2020/2020.02.10/#introduction","text":"Let's go one step further by continuing the question from last week. A question asked by algorithmic traders quite often is how many open orders are live on market at any given time.","title":"Introduction"},{"location":"2020/2020.02.10/#question","text":"Find the time series of the number of open child orders. The question from last week is simply a special case of this question. The output is a table with two columns like below: startTime nOpenOrders 09:30:00.000 0 hh:mm:ss.SSS x hh:mm:ss.SSS y hh:mm:ss.SSS z","title":"Question"},{"location":"2020/2020.02.10/#answer","text":"The child order count should increase by 1 at each order's submission time ( subT ) and decrease by 1 when the order is removed from the market at exit time ( exitT ). Based on this reasoning logic, three tables are created: The first table contains one row, which has order count of zero to accommodate the time period from market open to the time when the first child order is created. The second table contains all new orders. The third table records all orders which are removed from market. Along this line of thinking, the following implementation is suggested: initOrder:([] time:enlist openTime;nOpenOrders:enlist 0); addOrder:select time:subTime,nOpenOrders:1 from simOrders; removeOrder:select time:exitTime,nOpenOrders:-1 from simOrders; orders:select time,sums nOpenOrders from `time xasc initOrder,addOrder,removeOrder; select time,nOpenOrders from orders where differ nOpenOrders The where differ nOpenOrders on the last line above is required to make sure the order count between two consecutive rows are different.","title":"Answer"},{"location":"2020/2020.02.10a/","text":"Answer \u00b6 The child order count should increase by 1 at each order's submission time ( subT ) and decrease by 1 when the order is removed from the market at exit time ( exitT ). Based on this reasoning logic, three tables are created: The first table contains one row, which has order count of zero to accommodate the time period from market open to the time when the first child order is created. The second table contains all new orders. The third table records all orders which are removed from market. Along this line of thinking, the following implementation is suggested: initOrder:([] time:enlist openTime;nOpenOrders:enlist 0); addOrder:select time:subTime,nOpenOrders:1 from simOrders; removeOrder:select time:exitTime,nOpenOrders:-1 from simOrders; orders:select time,sums nOpenOrders from `time xasc initOrder,addOrder,removeOrder; select time,nOpenOrders from orders where differ nOpenOrders The where differ nOpenOrders on the last line above is required to make sure the order count between two consecutive rows are different.","title":"2020.02.10a"},{"location":"2020/2020.02.10a/#answer","text":"The child order count should increase by 1 at each order's submission time ( subT ) and decrease by 1 when the order is removed from the market at exit time ( exitT ). Based on this reasoning logic, three tables are created: The first table contains one row, which has order count of zero to accommodate the time period from market open to the time when the first child order is created. The second table contains all new orders. The third table records all orders which are removed from market. Along this line of thinking, the following implementation is suggested: initOrder:([] time:enlist openTime;nOpenOrders:enlist 0); addOrder:select time:subTime,nOpenOrders:1 from simOrders; removeOrder:select time:exitTime,nOpenOrders:-1 from simOrders; orders:select time,sums nOpenOrders from `time xasc initOrder,addOrder,removeOrder; select time,nOpenOrders from orders where differ nOpenOrders The where differ nOpenOrders on the last line above is required to make sure the order count between two consecutive rows are different.","title":"Answer"},{"location":"2020/2020.02.10q/","text":"Source: adopted from here Introduction \u00b6 Let's go one step further by continuing the question from last week. A question asked by algorithmic traders quite often is how many open orders are live on market at any given time. Question \u00b6 Find the time series of the number of open child orders. The question from last week is simply a special case of this question. The output is a table with two columns like below: startTime nOpenOrders 09:30:00.000 0 hh:mm:ss.SSS x hh:mm:ss.SSS y hh:mm:ss.SSS z","title":"2020.02.10q"},{"location":"2020/2020.02.10q/#introduction","text":"Let's go one step further by continuing the question from last week. A question asked by algorithmic traders quite often is how many open orders are live on market at any given time.","title":"Introduction"},{"location":"2020/2020.02.10q/#question","text":"Find the time series of the number of open child orders. The question from last week is simply a special case of this question. The output is a table with two columns like below: startTime nOpenOrders 09:30:00.000 0 hh:mm:ss.SSS x hh:mm:ss.SSS y hh:mm:ss.SSS z","title":"Question"},{"location":"2020/2020.02.17/","text":"Source: adopted from here Introduction \u00b6 In the algorithmic trading world, parameterization is so common that some algorithms are configured with hundreds or thousands of parameters. An algorithmic parent order can easily has hundreds of parameters and some of which are exposed to algorithm users so that they can update the order attributes. For example, the participation rate of a POV (Percent Of Volume) order can be amended by end users at any time during the trading duration. A common question encountered in the analysis of algorithm and/or smart order router behavior is what parameters are modified, and how they are updated when an amend event is initiated by an algorithmic trader. Question \u00b6 Below is an example history of a few selected parameters of a POV order. Create a table to show the parameter history with each parameter name as the column name in the table. You need to treat the change in order quantity and/or price limit the same as parameter change. paramTbl:([]time:`time$();orderQty:`long$();limitPrice:`float$();params:()); `paramTbl insert (09:30:56.123;500000;0n;`StartTime`PovRate!(10:00:00.000;0.08)); `paramTbl insert (09:35:44.735;500000;0n;`StartTime`PovRate!(09:40:00.000;0.08)); `paramTbl insert (10:01:25.941;500000;0n;`StartTime`PovRate!(09:40:00.000;0.12)); `paramTbl insert (10:10:32.356;500000;0n;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (10:30:39.475;500000;45.23;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;600000;45.27;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;1000000;0n;`StartTime`PovRate!(09:40:00.000;0.15)); The final output table should look like as follows. Note in kdb table, the empty cell in the table below should have proper null value. time OrderQty LimitPrice StartTime PovRate MinPovRate MaxPovRate 09:30:56.123 500000 10:00:00.000 0.08 09:35:44.735 500000 09:40:00.000 0.08 10:01:25.941 500000 09:40:00.000 0.12 10:10:32.356 500000 09:40:00.000 0.12 0.1 0.14 10:30:39.475 500000 45.23 09:40:00.000 0.12 0.1 0.14 11:00:52.092 600000 45.27 09:40:00.000 0.12 0.1 0.14 11:00:52.092 1000000 09:40:00.000 0.15 Answer \u00b6 The answer below shows a few tips on dictionary manipulation: Use raze to merge a list of dictionaries with values of possible different types into a single dictionary Find the proper null values for each dictionary key Merge two dictionaries with join operator Merge two tables side by side {[paramTbl] / Merge all parameters into a single dictionary so as to get a full list of parameter names allParams:raze exec params from paramTbl; / Find the null value for each parameter name nullValues:(key allParams)!(enlist each value allParams)[;1]; / Create a table of \"parameter\" change history of order qty and limit price params1:select time,OrderQty:orderQty,LimitPrice:limitPrice from paramTbl; / Set a proper null value to parameters that are not present params2:exec {x,y}[nullValues;] each params from paramTbl; / Combine the normal parameters with the pseudo parameters params1,'params2 }[paramTbl]","title":"2020.02.17"},{"location":"2020/2020.02.17/#introduction","text":"In the algorithmic trading world, parameterization is so common that some algorithms are configured with hundreds or thousands of parameters. An algorithmic parent order can easily has hundreds of parameters and some of which are exposed to algorithm users so that they can update the order attributes. For example, the participation rate of a POV (Percent Of Volume) order can be amended by end users at any time during the trading duration. A common question encountered in the analysis of algorithm and/or smart order router behavior is what parameters are modified, and how they are updated when an amend event is initiated by an algorithmic trader.","title":"Introduction"},{"location":"2020/2020.02.17/#question","text":"Below is an example history of a few selected parameters of a POV order. Create a table to show the parameter history with each parameter name as the column name in the table. You need to treat the change in order quantity and/or price limit the same as parameter change. paramTbl:([]time:`time$();orderQty:`long$();limitPrice:`float$();params:()); `paramTbl insert (09:30:56.123;500000;0n;`StartTime`PovRate!(10:00:00.000;0.08)); `paramTbl insert (09:35:44.735;500000;0n;`StartTime`PovRate!(09:40:00.000;0.08)); `paramTbl insert (10:01:25.941;500000;0n;`StartTime`PovRate!(09:40:00.000;0.12)); `paramTbl insert (10:10:32.356;500000;0n;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (10:30:39.475;500000;45.23;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;600000;45.27;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;1000000;0n;`StartTime`PovRate!(09:40:00.000;0.15)); The final output table should look like as follows. Note in kdb table, the empty cell in the table below should have proper null value. time OrderQty LimitPrice StartTime PovRate MinPovRate MaxPovRate 09:30:56.123 500000 10:00:00.000 0.08 09:35:44.735 500000 09:40:00.000 0.08 10:01:25.941 500000 09:40:00.000 0.12 10:10:32.356 500000 09:40:00.000 0.12 0.1 0.14 10:30:39.475 500000 45.23 09:40:00.000 0.12 0.1 0.14 11:00:52.092 600000 45.27 09:40:00.000 0.12 0.1 0.14 11:00:52.092 1000000 09:40:00.000 0.15","title":"Question"},{"location":"2020/2020.02.17/#answer","text":"The answer below shows a few tips on dictionary manipulation: Use raze to merge a list of dictionaries with values of possible different types into a single dictionary Find the proper null values for each dictionary key Merge two dictionaries with join operator Merge two tables side by side {[paramTbl] / Merge all parameters into a single dictionary so as to get a full list of parameter names allParams:raze exec params from paramTbl; / Find the null value for each parameter name nullValues:(key allParams)!(enlist each value allParams)[;1]; / Create a table of \"parameter\" change history of order qty and limit price params1:select time,OrderQty:orderQty,LimitPrice:limitPrice from paramTbl; / Set a proper null value to parameters that are not present params2:exec {x,y}[nullValues;] each params from paramTbl; / Combine the normal parameters with the pseudo parameters params1,'params2 }[paramTbl]","title":"Answer"},{"location":"2020/2020.02.17a/","text":"Answer \u00b6 The answer below shows a few tips on dictionary manipulation: Use raze to merge a list of dictionaries with values of possible different types into a single dictionary Find the proper null values for each dictionary key Merge two dictionaries with join operator Merge two tables side by side {[paramTbl] / Merge all parameters into a single dictionary so as to get a full list of parameter names allParams:raze exec params from paramTbl; / Find the null value for each parameter name nullValues:(key allParams)!(enlist each value allParams)[;1]; / Create a table of \"parameter\" change history of order qty and limit price params1:select time,OrderQty:orderQty,LimitPrice:limitPrice from paramTbl; / Set a proper null value to parameters that are not present params2:exec {x,y}[nullValues;] each params from paramTbl; / Combine the normal parameters with the pseudo parameters params1,'params2 }[paramTbl]","title":"2020.02.17a"},{"location":"2020/2020.02.17a/#answer","text":"The answer below shows a few tips on dictionary manipulation: Use raze to merge a list of dictionaries with values of possible different types into a single dictionary Find the proper null values for each dictionary key Merge two dictionaries with join operator Merge two tables side by side {[paramTbl] / Merge all parameters into a single dictionary so as to get a full list of parameter names allParams:raze exec params from paramTbl; / Find the null value for each parameter name nullValues:(key allParams)!(enlist each value allParams)[;1]; / Create a table of \"parameter\" change history of order qty and limit price params1:select time,OrderQty:orderQty,LimitPrice:limitPrice from paramTbl; / Set a proper null value to parameters that are not present params2:exec {x,y}[nullValues;] each params from paramTbl; / Combine the normal parameters with the pseudo parameters params1,'params2 }[paramTbl]","title":"Answer"},{"location":"2020/2020.02.17q/","text":"Source: adopted from here Introduction \u00b6 In the algorithmic trading world, parameterization is so common that some algorithms are configured with hundreds or thousands of parameters. An algorithmic parent order can easily has hundreds of parameters and some of which are exposed to algorithm users so that they can update the order attributes. For example, the participation rate of a POV (Percent Of Volume) order can be amended by end users at any time during the trading duration. A common question encountered in the analysis of algorithm and/or smart order router behavior is what parameters are modified, and how they are updated when an amend event is initiated by an algorithmic trader. Question \u00b6 Below is an example history of a few selected parameters of a POV order. Create a table to show the parameter history with each parameter name as the column name in the table. You need to treat the change in order quantity and/or price limit the same as parameter change. paramTbl:([]time:`time$();orderQty:`long$();limitPrice:`float$();params:()); `paramTbl insert (09:30:56.123;500000;0n;`StartTime`PovRate!(10:00:00.000;0.08)); `paramTbl insert (09:35:44.735;500000;0n;`StartTime`PovRate!(09:40:00.000;0.08)); `paramTbl insert (10:01:25.941;500000;0n;`StartTime`PovRate!(09:40:00.000;0.12)); `paramTbl insert (10:10:32.356;500000;0n;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (10:30:39.475;500000;45.23;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;600000;45.27;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;1000000;0n;`StartTime`PovRate!(09:40:00.000;0.15)); The final output table should look like as follows. Note in kdb table, the empty cell in the table below should have proper null value. time OrderQty LimitPrice StartTime PovRate MinPovRate MaxPovRate 09:30:56.123 500000 10:00:00.000 0.08 09:35:44.735 500000 09:40:00.000 0.08 10:01:25.941 500000 09:40:00.000 0.12 10:10:32.356 500000 09:40:00.000 0.12 0.1 0.14 10:30:39.475 500000 45.23 09:40:00.000 0.12 0.1 0.14 11:00:52.092 600000 45.27 09:40:00.000 0.12 0.1 0.14 11:00:52.092 1000000 09:40:00.000 0.15","title":"2020.02.17q"},{"location":"2020/2020.02.17q/#introduction","text":"In the algorithmic trading world, parameterization is so common that some algorithms are configured with hundreds or thousands of parameters. An algorithmic parent order can easily has hundreds of parameters and some of which are exposed to algorithm users so that they can update the order attributes. For example, the participation rate of a POV (Percent Of Volume) order can be amended by end users at any time during the trading duration. A common question encountered in the analysis of algorithm and/or smart order router behavior is what parameters are modified, and how they are updated when an amend event is initiated by an algorithmic trader.","title":"Introduction"},{"location":"2020/2020.02.17q/#question","text":"Below is an example history of a few selected parameters of a POV order. Create a table to show the parameter history with each parameter name as the column name in the table. You need to treat the change in order quantity and/or price limit the same as parameter change. paramTbl:([]time:`time$();orderQty:`long$();limitPrice:`float$();params:()); `paramTbl insert (09:30:56.123;500000;0n;`StartTime`PovRate!(10:00:00.000;0.08)); `paramTbl insert (09:35:44.735;500000;0n;`StartTime`PovRate!(09:40:00.000;0.08)); `paramTbl insert (10:01:25.941;500000;0n;`StartTime`PovRate!(09:40:00.000;0.12)); `paramTbl insert (10:10:32.356;500000;0n;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (10:30:39.475;500000;45.23;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;600000;45.27;`StartTime`PovRate`MinPovRate`MaxPovRate!(09:40:00.000;0.12;0.10;0.14)); `paramTbl insert (11:00:52.092;1000000;0n;`StartTime`PovRate!(09:40:00.000;0.15)); The final output table should look like as follows. Note in kdb table, the empty cell in the table below should have proper null value. time OrderQty LimitPrice StartTime PovRate MinPovRate MaxPovRate 09:30:56.123 500000 10:00:00.000 0.08 09:35:44.735 500000 09:40:00.000 0.08 10:01:25.941 500000 09:40:00.000 0.12 10:10:32.356 500000 09:40:00.000 0.12 0.1 0.14 10:30:39.475 500000 45.23 09:40:00.000 0.12 0.1 0.14 11:00:52.092 600000 45.27 09:40:00.000 0.12 0.1 0.14 11:00:52.092 1000000 09:40:00.000 0.15","title":"Question"},{"location":"2020/2020.02.24/","text":"Source: adopted from here Introduction \u00b6 One common operation on a dictionary is to add an new key to an existing dictionary. This operation looks quite easy and straightforward at first sight, but there is a trap to fall into. Question \u00b6 Suppose you have a dictionary d defined as follows: q) d:`firstName`lastName!`Tom`Jerry How to add a new key age with value 37 to this dictionary? After adding the new key, the updated dictionary should look like: q) d firstName| Tom lastName | Jerry age | 37 Answer \u00b6 The immediate solution that comes to many people's mind is to add the new key age is: q) d[`age]:37 Unfortunately, a type error is thrown when doing that: q) d[`age]:37 'type [0] d[`age]:37 ^ The type error occurs because: The existing dictionary d is uniform, and The value type of new item age is different from the value type of the existing items in the dictionary Let's look at two different cases. Mixed Value Type \u00b6 A new key can be simply added by assigning the value to the new key when the existing dictionary's values are of mixed types. For example, the value of dictionary d2 has types of symbol and long , i.e. , (`Tom;`Jerry;10583) is of mixed type. q) d2:`firstName`lastName`zip!(`Tom;`Jerry;10583) q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 q) d2[`age]:37 / add a new item q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 age | 37 Uniform Value Type \u00b6 The new value has the same type as the existing dictionary's value q) d3:`firstName`lastName!`Tom`Jerry q) d3[`state]:`NY q) d3 firstName| Tom lastName | Jerry state | NY The new value's type is different from the type of the existing dictionary's value. In this case, we can create a second dictionary using the new key/value and then merge this dictionary with the existing dictionary. For example, q) d4:`firstName`lastName!`Tom`Jerry q) d4 firstName| Tom lastName | Jerry q) d4,(enlist `age)!(enlist 37) firstName| `Tom lastName | `Jerry age | 37 The right side of the join operator ( , ) above is a singleton dictionary. Note that both the key and the value of a dictionary are required to be lists, you must enlist atomic value to create a singleton dictionary. A generic approach \u00b6 The q-sql update template can be used to update a dictionary: update age:37,zipcode:10583,address:\"231 Park Ave\" from d This approach is very generic and works irrespective the value types of the existing dictionary. Summary \u00b6 The robust approaches to insert a new item into an dictionary are: first create a new dictionary using the new item and merge this new dictionary with the existing dictionary using the join operator . use q-sql the update template to add new items to a dictionary or update the value of an existing item.","title":"2020.02.24"},{"location":"2020/2020.02.24/#introduction","text":"One common operation on a dictionary is to add an new key to an existing dictionary. This operation looks quite easy and straightforward at first sight, but there is a trap to fall into.","title":"Introduction"},{"location":"2020/2020.02.24/#question","text":"Suppose you have a dictionary d defined as follows: q) d:`firstName`lastName!`Tom`Jerry How to add a new key age with value 37 to this dictionary? After adding the new key, the updated dictionary should look like: q) d firstName| Tom lastName | Jerry age | 37","title":"Question"},{"location":"2020/2020.02.24/#answer","text":"The immediate solution that comes to many people's mind is to add the new key age is: q) d[`age]:37 Unfortunately, a type error is thrown when doing that: q) d[`age]:37 'type [0] d[`age]:37 ^ The type error occurs because: The existing dictionary d is uniform, and The value type of new item age is different from the value type of the existing items in the dictionary Let's look at two different cases.","title":"Answer"},{"location":"2020/2020.02.24/#mixed-value-type","text":"A new key can be simply added by assigning the value to the new key when the existing dictionary's values are of mixed types. For example, the value of dictionary d2 has types of symbol and long , i.e. , (`Tom;`Jerry;10583) is of mixed type. q) d2:`firstName`lastName`zip!(`Tom;`Jerry;10583) q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 q) d2[`age]:37 / add a new item q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 age | 37","title":"Mixed Value Type"},{"location":"2020/2020.02.24/#uniform-value-type","text":"The new value has the same type as the existing dictionary's value q) d3:`firstName`lastName!`Tom`Jerry q) d3[`state]:`NY q) d3 firstName| Tom lastName | Jerry state | NY The new value's type is different from the type of the existing dictionary's value. In this case, we can create a second dictionary using the new key/value and then merge this dictionary with the existing dictionary. For example, q) d4:`firstName`lastName!`Tom`Jerry q) d4 firstName| Tom lastName | Jerry q) d4,(enlist `age)!(enlist 37) firstName| `Tom lastName | `Jerry age | 37 The right side of the join operator ( , ) above is a singleton dictionary. Note that both the key and the value of a dictionary are required to be lists, you must enlist atomic value to create a singleton dictionary.","title":"Uniform Value Type"},{"location":"2020/2020.02.24/#a-generic-approach","text":"The q-sql update template can be used to update a dictionary: update age:37,zipcode:10583,address:\"231 Park Ave\" from d This approach is very generic and works irrespective the value types of the existing dictionary.","title":"A generic approach"},{"location":"2020/2020.02.24/#summary","text":"The robust approaches to insert a new item into an dictionary are: first create a new dictionary using the new item and merge this new dictionary with the existing dictionary using the join operator . use q-sql the update template to add new items to a dictionary or update the value of an existing item.","title":"Summary"},{"location":"2020/2020.02.24a/","text":"Answer \u00b6 The immediate solution that comes to many people's mind is to add the new key age is: q) d[`age]:37 Unfortunately, a type error is thrown when doing that: q) d[`age]:37 'type [0] d[`age]:37 ^ The type error occurs because: The existing dictionary d is uniform, and The value type of new item age is different from the value type of the existing items in the dictionary Let's look at two different cases. Mixed Value Type \u00b6 A new key can be simply added by assigning the value to the new key when the existing dictionary's values are of mixed types. For example, the value of dictionary d2 has types of symbol and long , i.e. , (`Tom;`Jerry;10583) is of mixed type. q) d2:`firstName`lastName`zip!(`Tom;`Jerry;10583) q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 q) d2[`age]:37 / add a new item q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 age | 37 Uniform Value Type \u00b6 The new value has the same type as the existing dictionary's value q) d3:`firstName`lastName!`Tom`Jerry q) d3[`state]:`NY q) d3 firstName| Tom lastName | Jerry state | NY The new value's type is different from the type of the existing dictionary's value. In this case, we can create a second dictionary using the new key/value and then merge this dictionary with the existing dictionary. For example, q) d4:`firstName`lastName!`Tom`Jerry q) d4 firstName| Tom lastName | Jerry q) d4,(enlist `age)!(enlist 37) firstName| `Tom lastName | `Jerry age | 37 The right side of the join operator ( , ) above is a singleton dictionary. Note that both the key and the value of a dictionary are required to be lists, you must enlist atomic value to create a singleton dictionary. A generic approach \u00b6 The q-sql update template can be used to update a dictionary: update age:37,zipcode:10583,address:\"231 Park Ave\" from d This approach is very generic and works irrespective the value types of the existing dictionary. Summary \u00b6 The robust approaches to insert a new item into an dictionary are: first create a new dictionary using the new item and merge this new dictionary with the existing dictionary using the join operator . use q-sql the update template to add new items to a dictionary or update the value of an existing item.","title":"2020.02.24a"},{"location":"2020/2020.02.24a/#answer","text":"The immediate solution that comes to many people's mind is to add the new key age is: q) d[`age]:37 Unfortunately, a type error is thrown when doing that: q) d[`age]:37 'type [0] d[`age]:37 ^ The type error occurs because: The existing dictionary d is uniform, and The value type of new item age is different from the value type of the existing items in the dictionary Let's look at two different cases.","title":"Answer"},{"location":"2020/2020.02.24a/#mixed-value-type","text":"A new key can be simply added by assigning the value to the new key when the existing dictionary's values are of mixed types. For example, the value of dictionary d2 has types of symbol and long , i.e. , (`Tom;`Jerry;10583) is of mixed type. q) d2:`firstName`lastName`zip!(`Tom;`Jerry;10583) q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 q) d2[`age]:37 / add a new item q) d2 firstName| `Tom lastName | `Jerry zipcode | 10583 age | 37","title":"Mixed Value Type"},{"location":"2020/2020.02.24a/#uniform-value-type","text":"The new value has the same type as the existing dictionary's value q) d3:`firstName`lastName!`Tom`Jerry q) d3[`state]:`NY q) d3 firstName| Tom lastName | Jerry state | NY The new value's type is different from the type of the existing dictionary's value. In this case, we can create a second dictionary using the new key/value and then merge this dictionary with the existing dictionary. For example, q) d4:`firstName`lastName!`Tom`Jerry q) d4 firstName| Tom lastName | Jerry q) d4,(enlist `age)!(enlist 37) firstName| `Tom lastName | `Jerry age | 37 The right side of the join operator ( , ) above is a singleton dictionary. Note that both the key and the value of a dictionary are required to be lists, you must enlist atomic value to create a singleton dictionary.","title":"Uniform Value Type"},{"location":"2020/2020.02.24a/#a-generic-approach","text":"The q-sql update template can be used to update a dictionary: update age:37,zipcode:10583,address:\"231 Park Ave\" from d This approach is very generic and works irrespective the value types of the existing dictionary.","title":"A generic approach"},{"location":"2020/2020.02.24a/#summary","text":"The robust approaches to insert a new item into an dictionary are: first create a new dictionary using the new item and merge this new dictionary with the existing dictionary using the join operator . use q-sql the update template to add new items to a dictionary or update the value of an existing item.","title":"Summary"},{"location":"2020/2020.02.24q/","text":"Source: adopted from here Introduction \u00b6 One common operation on a dictionary is to add an new key to an existing dictionary. This operation looks quite easy and straightforward at first sight, but there is a trap to fall into. Question \u00b6 Suppose you have a dictionary d defined as follows: q) d:`firstName`lastName!`Tom`Jerry How to add a new key age with value 37 to this dictionary? After adding the new key, the updated dictionary should look like: q) d firstName| Tom lastName | Jerry age | 37","title":"2020.02.24q"},{"location":"2020/2020.02.24q/#introduction","text":"One common operation on a dictionary is to add an new key to an existing dictionary. This operation looks quite easy and straightforward at first sight, but there is a trap to fall into.","title":"Introduction"},{"location":"2020/2020.02.24q/#question","text":"Suppose you have a dictionary d defined as follows: q) d:`firstName`lastName!`Tom`Jerry How to add a new key age with value 37 to this dictionary? After adding the new key, the updated dictionary should look like: q) d firstName| Tom lastName | Jerry age | 37","title":"Question"},{"location":"2020/2020.03.02/","text":"Source: adopted from here Introduction \u00b6 The first thing to do in most quantitative analysis in the electronic trading is to determine the data scope, which covers two aspects: the sample period, i.e. the start and end date/time of the data the cross sectional space, i.e. the universe of securities included in the analysis A common approach to determine the security universe is to include the top n most actively traded symbols. Question \u00b6 Assuming a trade table, which has three columns: date , ticker and volume , is simulated with the function simulateTrades defined below. This function generates 500000 trades for all week days in March 2020. The stock ticker is generated as three random letters. The column volume indicates how many shares are traded. getTradingDays:{ firstDate:2020.03.01; lastDate:2020.03.31; dates:firstDate+til (lastDate-firstDate)+1; dates where not (dates mod 7) in 0 1 }; simulateTrades:{[seed;nTrades] tradingDays:getTradingDays[]; system \"S \",string seed; dates:nTrades?tradingDays; system \"S \",string seed; tickers:nTrades?`3; system \"S \",string seed; volumes:100*nTrades?1+til 100; ([] date:dates;ticker:tickers;volume:volumes) }; trades:simulateTrades[-314159;5000000] Find the top 10 symbols that are most actively traded (measured by total traded shares) on each day. The returned table should have 220 rows, i.e. 10 rows for each day and the following schema: topTradedSymbols:([] date:`date$(); ticker:`symbol$(); dailyVol:`long$() ) Answer \u00b6 First we compute the daily volume from the trade tick data and sort the volume in descending order for each date. Note that 0! is used to remove the key from the table. dailyVolume:`date`dailyVol xdesc 0!select dailyVol:sum volume by date,ticker from trades; Below four different approaches are provided to find the top 10 most actively trades symbols. Use fby \u00b6 Find the first 10 indices on each day and then filter out these rows. select from dailyVolume where ({x in 10#x};i) fby date Use sublist \u00b6 ungroup select sublist[10] ticker,sublist[10] dailyVol by date from dailyVolume Use # \u00b6 Given sublist is implemented internally with take operator, using # directly is slightly faster than using sublist . ungroup select 10#ticker,10#dailyVol by date from dailyVolume Use group \u00b6 select from dailyVolume where i in raze 10#/:group date Remarks \u00b6 The last approach using group is preferred due to two reasons: it runs fastest it is cleaner if multiple columns are present in the table","title":"2020.03.02"},{"location":"2020/2020.03.02/#introduction","text":"The first thing to do in most quantitative analysis in the electronic trading is to determine the data scope, which covers two aspects: the sample period, i.e. the start and end date/time of the data the cross sectional space, i.e. the universe of securities included in the analysis A common approach to determine the security universe is to include the top n most actively traded symbols.","title":"Introduction"},{"location":"2020/2020.03.02/#question","text":"Assuming a trade table, which has three columns: date , ticker and volume , is simulated with the function simulateTrades defined below. This function generates 500000 trades for all week days in March 2020. The stock ticker is generated as three random letters. The column volume indicates how many shares are traded. getTradingDays:{ firstDate:2020.03.01; lastDate:2020.03.31; dates:firstDate+til (lastDate-firstDate)+1; dates where not (dates mod 7) in 0 1 }; simulateTrades:{[seed;nTrades] tradingDays:getTradingDays[]; system \"S \",string seed; dates:nTrades?tradingDays; system \"S \",string seed; tickers:nTrades?`3; system \"S \",string seed; volumes:100*nTrades?1+til 100; ([] date:dates;ticker:tickers;volume:volumes) }; trades:simulateTrades[-314159;5000000] Find the top 10 symbols that are most actively traded (measured by total traded shares) on each day. The returned table should have 220 rows, i.e. 10 rows for each day and the following schema: topTradedSymbols:([] date:`date$(); ticker:`symbol$(); dailyVol:`long$() )","title":"Question"},{"location":"2020/2020.03.02/#answer","text":"First we compute the daily volume from the trade tick data and sort the volume in descending order for each date. Note that 0! is used to remove the key from the table. dailyVolume:`date`dailyVol xdesc 0!select dailyVol:sum volume by date,ticker from trades; Below four different approaches are provided to find the top 10 most actively trades symbols.","title":"Answer"},{"location":"2020/2020.03.02/#use-fby","text":"Find the first 10 indices on each day and then filter out these rows. select from dailyVolume where ({x in 10#x};i) fby date","title":"Use fby"},{"location":"2020/2020.03.02/#use-sublist","text":"ungroup select sublist[10] ticker,sublist[10] dailyVol by date from dailyVolume","title":"Use sublist"},{"location":"2020/2020.03.02/#use","text":"Given sublist is implemented internally with take operator, using # directly is slightly faster than using sublist . ungroup select 10#ticker,10#dailyVol by date from dailyVolume","title":"Use #"},{"location":"2020/2020.03.02/#use-group","text":"select from dailyVolume where i in raze 10#/:group date","title":"Use group"},{"location":"2020/2020.03.02/#remarks","text":"The last approach using group is preferred due to two reasons: it runs fastest it is cleaner if multiple columns are present in the table","title":"Remarks"},{"location":"2020/2020.03.02a/","text":"Answer \u00b6 First we compute the daily volume from the trade tick data and sort the volume in descending order for each date. Note that 0! is used to remove the key from the table. dailyVolume:`date`dailyVol xdesc 0!select dailyVol:sum volume by date,ticker from trades; Below four different approaches are provided to find the top 10 most actively trades symbols. Use fby \u00b6 Find the first 10 indices on each day and then filter out these rows. select from dailyVolume where ({x in 10#x};i) fby date Use sublist \u00b6 ungroup select sublist[10] ticker,sublist[10] dailyVol by date from dailyVolume Use # \u00b6 Given sublist is implemented internally with take operator, using # directly is slightly faster than using sublist . ungroup select 10#ticker,10#dailyVol by date from dailyVolume Use group \u00b6 select from dailyVolume where i in raze 10#/:group date Remarks \u00b6 The last approach using group is preferred due to two reasons: it runs fastest it is cleaner if multiple columns are present in the table","title":"2020.03.02a"},{"location":"2020/2020.03.02a/#answer","text":"First we compute the daily volume from the trade tick data and sort the volume in descending order for each date. Note that 0! is used to remove the key from the table. dailyVolume:`date`dailyVol xdesc 0!select dailyVol:sum volume by date,ticker from trades; Below four different approaches are provided to find the top 10 most actively trades symbols.","title":"Answer"},{"location":"2020/2020.03.02a/#use-fby","text":"Find the first 10 indices on each day and then filter out these rows. select from dailyVolume where ({x in 10#x};i) fby date","title":"Use fby"},{"location":"2020/2020.03.02a/#use-sublist","text":"ungroup select sublist[10] ticker,sublist[10] dailyVol by date from dailyVolume","title":"Use sublist"},{"location":"2020/2020.03.02a/#use","text":"Given sublist is implemented internally with take operator, using # directly is slightly faster than using sublist . ungroup select 10#ticker,10#dailyVol by date from dailyVolume","title":"Use #"},{"location":"2020/2020.03.02a/#use-group","text":"select from dailyVolume where i in raze 10#/:group date","title":"Use group"},{"location":"2020/2020.03.02a/#remarks","text":"The last approach using group is preferred due to two reasons: it runs fastest it is cleaner if multiple columns are present in the table","title":"Remarks"},{"location":"2020/2020.03.02q/","text":"Source: adopted from here Introduction \u00b6 The first thing to do in most quantitative analysis in the electronic trading is to determine the data scope, which covers two aspects: the sample period, i.e. the start and end date/time of the data the cross sectional space, i.e. the universe of securities included in the analysis A common approach to determine the security universe is to include the top n most actively traded symbols. Question \u00b6 Assuming a trade table, which has three columns: date , ticker and volume , is simulated with the function simulateTrades defined below. This function generates 500000 trades for all week days in March 2020. The stock ticker is generated as three random letters. The column volume indicates how many shares are traded. getTradingDays:{ firstDate:2020.03.01; lastDate:2020.03.31; dates:firstDate+til (lastDate-firstDate)+1; dates where not (dates mod 7) in 0 1 }; simulateTrades:{[seed;nTrades] tradingDays:getTradingDays[]; system \"S \",string seed; dates:nTrades?tradingDays; system \"S \",string seed; tickers:nTrades?`3; system \"S \",string seed; volumes:100*nTrades?1+til 100; ([] date:dates;ticker:tickers;volume:volumes) }; trades:simulateTrades[-314159;5000000] Find the top 10 symbols that are most actively traded (measured by total traded shares) on each day. The returned table should have 220 rows, i.e. 10 rows for each day and the following schema: topTradedSymbols:([] date:`date$(); ticker:`symbol$(); dailyVol:`long$() )","title":"2020.03.02q"},{"location":"2020/2020.03.02q/#introduction","text":"The first thing to do in most quantitative analysis in the electronic trading is to determine the data scope, which covers two aspects: the sample period, i.e. the start and end date/time of the data the cross sectional space, i.e. the universe of securities included in the analysis A common approach to determine the security universe is to include the top n most actively traded symbols.","title":"Introduction"},{"location":"2020/2020.03.02q/#question","text":"Assuming a trade table, which has three columns: date , ticker and volume , is simulated with the function simulateTrades defined below. This function generates 500000 trades for all week days in March 2020. The stock ticker is generated as three random letters. The column volume indicates how many shares are traded. getTradingDays:{ firstDate:2020.03.01; lastDate:2020.03.31; dates:firstDate+til (lastDate-firstDate)+1; dates where not (dates mod 7) in 0 1 }; simulateTrades:{[seed;nTrades] tradingDays:getTradingDays[]; system \"S \",string seed; dates:nTrades?tradingDays; system \"S \",string seed; tickers:nTrades?`3; system \"S \",string seed; volumes:100*nTrades?1+til 100; ([] date:dates;ticker:tickers;volume:volumes) }; trades:simulateTrades[-314159;5000000] Find the top 10 symbols that are most actively traded (measured by total traded shares) on each day. The returned table should have 220 rows, i.e. 10 rows for each day and the following schema: topTradedSymbols:([] date:`date$(); ticker:`symbol$(); dailyVol:`long$() )","title":"Question"},{"location":"2020/2020.03.09/","text":"Source: adopted from here Introduction \u00b6 Sometimes the source data we have to deal with is given and we have no control on how the data is named, typed and stored. One example is there is a space in the table column name or a q keyword is used as the column name. In this case, querying the table becomes tricky. Question \u00b6 Below is a simple \"badly\" constructed table dataTbl , which has a column named order type , noting the space between the two words. dataList:( \"date,sym,order type,orderQty\" ;\"2020.03.09,AAPL.OQ,MID QUOTE,80000\" ;\"2020.03.09,AAPL.OQ,FAR TOUCH,50000\" ;\"2020.03.09,AAPL.OQ,NEAR TOUCH,120000\" ;\"2020.03.10,AAPL.OQ,MID QUOTE,100000\" ;\"2020.03.10,AAPL.OQ,FAR TOUCH,70000\" ;\"2020.03.10,AAPL.OQ,NEAR TOUCH,170000\" ;\"2020.03.09,IBM.N,MID QUOTE,83000\" ;\"2020.03.09,IBM.N,FAR TOUCH,54000\" ;\"2020.03.09,IBM.N,NEAR TOUCH,129000\" ;\"2020.03.10,IBM.N,MID QUOTE,130000\" ;\"2020.03.10,IBM.N,FAR TOUCH,79000\" ;\"2020.03.10,IBM.N,NEAR TOUCH,175000\" ;\"2020.03.09,BABA.N,MID QUOTE,120000\" ;\"2020.03.09,BABA.N,FAR TOUCH,68000\" ;\"2020.03.09,BABA.N,NEAR TOUCH,930000\" ;\"2020.03.10,BABA.N,MID QUOTE,150000\" ;\"2020.03.10,BABA.N,FAR TOUCH,96000\" ;\"2020.03.10,BABA.N,NEAR TOUCH,2030000\" ); dataTbl:(\"DSSJ\"; enlist \",\") 0:dataList; Answer the following two questions: Find the total order qty ( orderQty ) across all dates grouped by order type Find the total order qty for order type MID QUOTE , grouped by sym Answer \u00b6 When selecting from a \"problematic\" table with space in column name or keyword as column name, the classical select ... from ... template does not work. We have two ways to deal with tables like this. Functional Select \u00b6 The basic syntax of functional select is ?[t;a;b;c] where: t : a t able or table name a : a dictionary of a ggregates b : a dictionary of group b y c : a dictionary of c onstraints More details on functional select are here and here . Question 1 \u00b6 a:(); b:(enlist `orderType)!(enlist `$\"order type\"); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c] Question 2 \u00b6 a:(enlist (=;`$\"order type\";enlist `$\"MID QUOTE\")); b:(enlist `sym)!(enlist `sym); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c] Rename Columns \u00b6 We can use xcol to rename the column names. Also note that we need to caste the string \"MID QUOTE\" to a symbol since it contains a space. Question 1 \u00b6 select totalOrderQty:sum orderQty by orderType from `date`sym`orderType xcol dataTbl Question 2 \u00b6 select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType=`$\"MID QUOTE\" Alternatively, you can also use like to match a string pattern: select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType like \"MID QUOTE\" Note that using like is slower than the first approach. It is 20% slower when run from my machine for 10 million times.","title":"2020.03.09"},{"location":"2020/2020.03.09/#introduction","text":"Sometimes the source data we have to deal with is given and we have no control on how the data is named, typed and stored. One example is there is a space in the table column name or a q keyword is used as the column name. In this case, querying the table becomes tricky.","title":"Introduction"},{"location":"2020/2020.03.09/#question","text":"Below is a simple \"badly\" constructed table dataTbl , which has a column named order type , noting the space between the two words. dataList:( \"date,sym,order type,orderQty\" ;\"2020.03.09,AAPL.OQ,MID QUOTE,80000\" ;\"2020.03.09,AAPL.OQ,FAR TOUCH,50000\" ;\"2020.03.09,AAPL.OQ,NEAR TOUCH,120000\" ;\"2020.03.10,AAPL.OQ,MID QUOTE,100000\" ;\"2020.03.10,AAPL.OQ,FAR TOUCH,70000\" ;\"2020.03.10,AAPL.OQ,NEAR TOUCH,170000\" ;\"2020.03.09,IBM.N,MID QUOTE,83000\" ;\"2020.03.09,IBM.N,FAR TOUCH,54000\" ;\"2020.03.09,IBM.N,NEAR TOUCH,129000\" ;\"2020.03.10,IBM.N,MID QUOTE,130000\" ;\"2020.03.10,IBM.N,FAR TOUCH,79000\" ;\"2020.03.10,IBM.N,NEAR TOUCH,175000\" ;\"2020.03.09,BABA.N,MID QUOTE,120000\" ;\"2020.03.09,BABA.N,FAR TOUCH,68000\" ;\"2020.03.09,BABA.N,NEAR TOUCH,930000\" ;\"2020.03.10,BABA.N,MID QUOTE,150000\" ;\"2020.03.10,BABA.N,FAR TOUCH,96000\" ;\"2020.03.10,BABA.N,NEAR TOUCH,2030000\" ); dataTbl:(\"DSSJ\"; enlist \",\") 0:dataList; Answer the following two questions: Find the total order qty ( orderQty ) across all dates grouped by order type Find the total order qty for order type MID QUOTE , grouped by sym","title":"Question"},{"location":"2020/2020.03.09/#answer","text":"When selecting from a \"problematic\" table with space in column name or keyword as column name, the classical select ... from ... template does not work. We have two ways to deal with tables like this.","title":"Answer"},{"location":"2020/2020.03.09/#functional-select","text":"The basic syntax of functional select is ?[t;a;b;c] where: t : a t able or table name a : a dictionary of a ggregates b : a dictionary of group b y c : a dictionary of c onstraints More details on functional select are here and here .","title":"Functional Select"},{"location":"2020/2020.03.09/#question-1","text":"a:(); b:(enlist `orderType)!(enlist `$\"order type\"); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c]","title":"Question 1"},{"location":"2020/2020.03.09/#question-2","text":"a:(enlist (=;`$\"order type\";enlist `$\"MID QUOTE\")); b:(enlist `sym)!(enlist `sym); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c]","title":"Question 2"},{"location":"2020/2020.03.09/#rename-columns","text":"We can use xcol to rename the column names. Also note that we need to caste the string \"MID QUOTE\" to a symbol since it contains a space.","title":"Rename Columns"},{"location":"2020/2020.03.09/#question-1_1","text":"select totalOrderQty:sum orderQty by orderType from `date`sym`orderType xcol dataTbl","title":"Question 1"},{"location":"2020/2020.03.09/#question-2_1","text":"select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType=`$\"MID QUOTE\" Alternatively, you can also use like to match a string pattern: select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType like \"MID QUOTE\" Note that using like is slower than the first approach. It is 20% slower when run from my machine for 10 million times.","title":"Question 2"},{"location":"2020/2020.03.09a/","text":"Answer \u00b6 When selecting from a \"problematic\" table with space in column name or keyword as column name, the classical select ... from ... template does not work. We have two ways to deal with tables like this. Functional Select \u00b6 The basic syntax of functional select is ?[t;a;b;c] where: t : a t able or table name a : a dictionary of a ggregates b : a dictionary of group b y c : a dictionary of c onstraints More details on functional select are here and here . Question 1 \u00b6 a:(); b:(enlist `orderType)!(enlist `$\"order type\"); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c] Question 2 \u00b6 a:(enlist (=;`$\"order type\";enlist `$\"MID QUOTE\")); b:(enlist `sym)!(enlist `sym); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c] Rename Columns \u00b6 We can use xcol to rename the column names. Also note that we need to caste the string \"MID QUOTE\" to a symbol since it contains a space. Question 1 \u00b6 select totalOrderQty:sum orderQty by orderType from `date`sym`orderType xcol dataTbl Question 2 \u00b6 select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType=`$\"MID QUOTE\" Alternatively, you can also use like to match a string pattern: select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType like \"MID QUOTE\" Note that using like is slower than the first approach. It is 20% slower when run from my machine for 10 million times.","title":"2020.03.09a"},{"location":"2020/2020.03.09a/#answer","text":"When selecting from a \"problematic\" table with space in column name or keyword as column name, the classical select ... from ... template does not work. We have two ways to deal with tables like this.","title":"Answer"},{"location":"2020/2020.03.09a/#functional-select","text":"The basic syntax of functional select is ?[t;a;b;c] where: t : a t able or table name a : a dictionary of a ggregates b : a dictionary of group b y c : a dictionary of c onstraints More details on functional select are here and here .","title":"Functional Select"},{"location":"2020/2020.03.09a/#question-1","text":"a:(); b:(enlist `orderType)!(enlist `$\"order type\"); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c]","title":"Question 1"},{"location":"2020/2020.03.09a/#question-2","text":"a:(enlist (=;`$\"order type\";enlist `$\"MID QUOTE\")); b:(enlist `sym)!(enlist `sym); c:(enlist `totalOrderQty)!(enlist (sum;`orderQty)); ?[dataTbl;a;b;c]","title":"Question 2"},{"location":"2020/2020.03.09a/#rename-columns","text":"We can use xcol to rename the column names. Also note that we need to caste the string \"MID QUOTE\" to a symbol since it contains a space.","title":"Rename Columns"},{"location":"2020/2020.03.09a/#question-1_1","text":"select totalOrderQty:sum orderQty by orderType from `date`sym`orderType xcol dataTbl","title":"Question 1"},{"location":"2020/2020.03.09a/#question-2_1","text":"select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType=`$\"MID QUOTE\" Alternatively, you can also use like to match a string pattern: select totalOrderQty:sum orderQty by sym from ( `date`sym`orderType xcol dataTbl ) where orderType like \"MID QUOTE\" Note that using like is slower than the first approach. It is 20% slower when run from my machine for 10 million times.","title":"Question 2"},{"location":"2020/2020.03.09q/","text":"Source: adopted from here Introduction \u00b6 Sometimes the source data we have to deal with is given and we have no control on how the data is named, typed and stored. One example is there is a space in the table column name or a q keyword is used as the column name. In this case, querying the table becomes tricky. Question \u00b6 Below is a simple \"badly\" constructed table dataTbl , which has a column named order type , noting the space between the two words. dataList:( \"date,sym,order type,orderQty\" ;\"2020.03.09,AAPL.OQ,MID QUOTE,80000\" ;\"2020.03.09,AAPL.OQ,FAR TOUCH,50000\" ;\"2020.03.09,AAPL.OQ,NEAR TOUCH,120000\" ;\"2020.03.10,AAPL.OQ,MID QUOTE,100000\" ;\"2020.03.10,AAPL.OQ,FAR TOUCH,70000\" ;\"2020.03.10,AAPL.OQ,NEAR TOUCH,170000\" ;\"2020.03.09,IBM.N,MID QUOTE,83000\" ;\"2020.03.09,IBM.N,FAR TOUCH,54000\" ;\"2020.03.09,IBM.N,NEAR TOUCH,129000\" ;\"2020.03.10,IBM.N,MID QUOTE,130000\" ;\"2020.03.10,IBM.N,FAR TOUCH,79000\" ;\"2020.03.10,IBM.N,NEAR TOUCH,175000\" ;\"2020.03.09,BABA.N,MID QUOTE,120000\" ;\"2020.03.09,BABA.N,FAR TOUCH,68000\" ;\"2020.03.09,BABA.N,NEAR TOUCH,930000\" ;\"2020.03.10,BABA.N,MID QUOTE,150000\" ;\"2020.03.10,BABA.N,FAR TOUCH,96000\" ;\"2020.03.10,BABA.N,NEAR TOUCH,2030000\" ); dataTbl:(\"DSSJ\"; enlist \",\") 0:dataList; Answer the following two questions: Find the total order qty ( orderQty ) across all dates grouped by order type Find the total order qty for order type MID QUOTE , grouped by sym","title":"2020.03.09q"},{"location":"2020/2020.03.09q/#introduction","text":"Sometimes the source data we have to deal with is given and we have no control on how the data is named, typed and stored. One example is there is a space in the table column name or a q keyword is used as the column name. In this case, querying the table becomes tricky.","title":"Introduction"},{"location":"2020/2020.03.09q/#question","text":"Below is a simple \"badly\" constructed table dataTbl , which has a column named order type , noting the space between the two words. dataList:( \"date,sym,order type,orderQty\" ;\"2020.03.09,AAPL.OQ,MID QUOTE,80000\" ;\"2020.03.09,AAPL.OQ,FAR TOUCH,50000\" ;\"2020.03.09,AAPL.OQ,NEAR TOUCH,120000\" ;\"2020.03.10,AAPL.OQ,MID QUOTE,100000\" ;\"2020.03.10,AAPL.OQ,FAR TOUCH,70000\" ;\"2020.03.10,AAPL.OQ,NEAR TOUCH,170000\" ;\"2020.03.09,IBM.N,MID QUOTE,83000\" ;\"2020.03.09,IBM.N,FAR TOUCH,54000\" ;\"2020.03.09,IBM.N,NEAR TOUCH,129000\" ;\"2020.03.10,IBM.N,MID QUOTE,130000\" ;\"2020.03.10,IBM.N,FAR TOUCH,79000\" ;\"2020.03.10,IBM.N,NEAR TOUCH,175000\" ;\"2020.03.09,BABA.N,MID QUOTE,120000\" ;\"2020.03.09,BABA.N,FAR TOUCH,68000\" ;\"2020.03.09,BABA.N,NEAR TOUCH,930000\" ;\"2020.03.10,BABA.N,MID QUOTE,150000\" ;\"2020.03.10,BABA.N,FAR TOUCH,96000\" ;\"2020.03.10,BABA.N,NEAR TOUCH,2030000\" ); dataTbl:(\"DSSJ\"; enlist \",\") 0:dataList; Answer the following two questions: Find the total order qty ( orderQty ) across all dates grouped by order type Find the total order qty for order type MID QUOTE , grouped by sym","title":"Question"},{"location":"2020/2020.03.16/","text":"Source: adopted from here Introduction \u00b6 I/O operation is one of the most common features supported by all programming languages. Reading from and writing to a file in q is extremely powerful and flexible. Reading a standard csv is quite straightforward and is covered extensively in Q For Mortals . However, the files we have to read sometimes are not standard and some pre-processing is required before they are loaded into kdb. Question \u00b6 NASDAQ publishes the listed symbols on its exchange on a daily basis. Download the text file nasdaqlisted.txt from here and save the file on your personal computer. The file you downloaded has a header and footer. For example Header Symbol|Security Name|Market Category|Test Issue|Financial Status|Round Lot Size|ETF|NextShares Footer File Creation Time: 0316202018:01||||||| Write a q script snippet to load this text file into kdb table nasdaqlisted with the following schema: q) meta nasdaqlisted | c | t f a | |----------------|-------| | symbol | s | | securityName | s | | marketCategory | s | | isTestIssue | b | | lotSize | j | | isETF | b | Answer \u00b6 The following q script snippet is proposed. On my machine, I save the file under C:\\data\\ . Note that the path separator in q is forward slash ( / ) on all Operating Systems including Windows, Linux, and Mac. infile:hsym `$\"C:/data/nasdaqlisted.txt\"; nasdaqlisted:(\"SSSB JB \";enlist \"|\") 0:-1_read0 infile; `symbol`securityName`marketCategory`isTestIssue`lotSize`isETF xcol nasdaqlisted Some additional details on a few keywords used in the answer: hsym is used to create a file handle from a symbol. read0 reads a text file and the last line is dropped with -1_ . 0: interprets a field-delimited list of strings as a matrix. Use a space to omit a field from the load if you don't want to load it. Use xcol to rename column name with space in it as discussed last week.","title":"2020.03.16"},{"location":"2020/2020.03.16/#introduction","text":"I/O operation is one of the most common features supported by all programming languages. Reading from and writing to a file in q is extremely powerful and flexible. Reading a standard csv is quite straightforward and is covered extensively in Q For Mortals . However, the files we have to read sometimes are not standard and some pre-processing is required before they are loaded into kdb.","title":"Introduction"},{"location":"2020/2020.03.16/#question","text":"NASDAQ publishes the listed symbols on its exchange on a daily basis. Download the text file nasdaqlisted.txt from here and save the file on your personal computer. The file you downloaded has a header and footer. For example Header Symbol|Security Name|Market Category|Test Issue|Financial Status|Round Lot Size|ETF|NextShares Footer File Creation Time: 0316202018:01||||||| Write a q script snippet to load this text file into kdb table nasdaqlisted with the following schema: q) meta nasdaqlisted | c | t f a | |----------------|-------| | symbol | s | | securityName | s | | marketCategory | s | | isTestIssue | b | | lotSize | j | | isETF | b |","title":"Question"},{"location":"2020/2020.03.16/#answer","text":"The following q script snippet is proposed. On my machine, I save the file under C:\\data\\ . Note that the path separator in q is forward slash ( / ) on all Operating Systems including Windows, Linux, and Mac. infile:hsym `$\"C:/data/nasdaqlisted.txt\"; nasdaqlisted:(\"SSSB JB \";enlist \"|\") 0:-1_read0 infile; `symbol`securityName`marketCategory`isTestIssue`lotSize`isETF xcol nasdaqlisted Some additional details on a few keywords used in the answer: hsym is used to create a file handle from a symbol. read0 reads a text file and the last line is dropped with -1_ . 0: interprets a field-delimited list of strings as a matrix. Use a space to omit a field from the load if you don't want to load it. Use xcol to rename column name with space in it as discussed last week.","title":"Answer"},{"location":"2020/2020.03.16a/","text":"Answer \u00b6 The following q script snippet is proposed. On my machine, I save the file under C:\\data\\ . Note that the path separator in q is forward slash ( / ) on all Operating Systems including Windows, Linux, and Mac. infile:hsym `$\"C:/data/nasdaqlisted.txt\"; nasdaqlisted:(\"SSSB JB \";enlist \"|\") 0:-1_read0 infile; `symbol`securityName`marketCategory`isTestIssue`lotSize`isETF xcol nasdaqlisted Some additional details on a few keywords used in the answer: hsym is used to create a file handle from a symbol. read0 reads a text file and the last line is dropped with -1_ . 0: interprets a field-delimited list of strings as a matrix. Use a space to omit a field from the load if you don't want to load it. Use xcol to rename column name with space in it as discussed last week.","title":"2020.03.16a"},{"location":"2020/2020.03.16a/#answer","text":"The following q script snippet is proposed. On my machine, I save the file under C:\\data\\ . Note that the path separator in q is forward slash ( / ) on all Operating Systems including Windows, Linux, and Mac. infile:hsym `$\"C:/data/nasdaqlisted.txt\"; nasdaqlisted:(\"SSSB JB \";enlist \"|\") 0:-1_read0 infile; `symbol`securityName`marketCategory`isTestIssue`lotSize`isETF xcol nasdaqlisted Some additional details on a few keywords used in the answer: hsym is used to create a file handle from a symbol. read0 reads a text file and the last line is dropped with -1_ . 0: interprets a field-delimited list of strings as a matrix. Use a space to omit a field from the load if you don't want to load it. Use xcol to rename column name with space in it as discussed last week.","title":"Answer"},{"location":"2020/2020.03.16q/","text":"Source: adopted from here Introduction \u00b6 I/O operation is one of the most common features supported by all programming languages. Reading from and writing to a file in q is extremely powerful and flexible. Reading a standard csv is quite straightforward and is covered extensively in Q For Mortals . However, the files we have to read sometimes are not standard and some pre-processing is required before they are loaded into kdb. Question \u00b6 NASDAQ publishes the listed symbols on its exchange on a daily basis. Download the text file nasdaqlisted.txt from here and save the file on your personal computer. The file you downloaded has a header and footer. For example Header Symbol|Security Name|Market Category|Test Issue|Financial Status|Round Lot Size|ETF|NextShares Footer File Creation Time: 0316202018:01||||||| Write a q script snippet to load this text file into kdb table nasdaqlisted with the following schema: q) meta nasdaqlisted | c | t f a | |----------------|-------| | symbol | s | | securityName | s | | marketCategory | s | | isTestIssue | b | | lotSize | j | | isETF | b |","title":"2020.03.16q"},{"location":"2020/2020.03.16q/#introduction","text":"I/O operation is one of the most common features supported by all programming languages. Reading from and writing to a file in q is extremely powerful and flexible. Reading a standard csv is quite straightforward and is covered extensively in Q For Mortals . However, the files we have to read sometimes are not standard and some pre-processing is required before they are loaded into kdb.","title":"Introduction"},{"location":"2020/2020.03.16q/#question","text":"NASDAQ publishes the listed symbols on its exchange on a daily basis. Download the text file nasdaqlisted.txt from here and save the file on your personal computer. The file you downloaded has a header and footer. For example Header Symbol|Security Name|Market Category|Test Issue|Financial Status|Round Lot Size|ETF|NextShares Footer File Creation Time: 0316202018:01||||||| Write a q script snippet to load this text file into kdb table nasdaqlisted with the following schema: q) meta nasdaqlisted | c | t f a | |----------------|-------| | symbol | s | | securityName | s | | marketCategory | s | | isTestIssue | b | | lotSize | j | | isETF | b |","title":"Question"},{"location":"2020/2020.03.23/","text":"Source: adopted from here Introduction \u00b6 Market Identifier Code (MIC) is an international standard, which \"specifies a universal method of identifying exchanges, trading platforms, regulated or non-regulated markets and trade reporting facilities as sources of prices and related information in order to facilitate automated processing\" as quoted from its official site . The U.S. Equities market has 13 lit exchanges and dozens of Alternative Trading Systems (ATSs), a.k.a. dark pools. Many buy side firms also operate their own non-ATS crossing systems. Question \u00b6 There might be multiple exchanges quoting at the National Best Bid and Offer (NBBO) price level at any given time. It is assumed that child orders are always placed at NBBO and can be placed to any lit exchanges. The below function simChildOrders simulates some BUY orders with execution destination ( exDest ). See the definition of FIX tag for exDest . It also has a column nbbExchanges , which shows the list of lit exchanges that are present at the best bid price level. simChildOrders:{[nOrders] seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exDest:nOrders?litVenues; system \"S \",string seed; nExchanges:3+nOrders?(count litVenues)-3; system \"S \",string seed; nbbVenues:{y?x}[litVenues;] each nExchanges; ([] time:submitTimes;side:`BUY;exDest:exDest;nbbVenues:nbbVenues) }; childOrders:simChildOrders[5000]; Find the number of orders which are placed to exchanges present at NBB (National Best Bid). Answer \u00b6 Use each both \u00b6 Learn more about each or each both here . exec sum in'[exDest;nbbVenues] from childOrders Each applied to a binary value is also called each both and the infix form can be used. exec sum exDest in' nbbVenues from childOrders Use where and any \u00b6 exec count i from childOrders where any each exDest=nbbVenues Use list argument \u00b6 Note that the anonymous function is unary and the parameter is a list. exec sum {x[0] in x[1]} each flip (exDest;nbbVenues) from childOrders Use operator apply . \u00b6 The operator apply . applies a function to a list and use the individual list elements as the arguments to the function. This is very much similar to * operator to unpack argument list to function call in Python and the spread operator ... in JavaScript . exec sum ({x in y}.) each flip (exDest;nbbVenues) from childOrders","title":"2020.03.23"},{"location":"2020/2020.03.23/#introduction","text":"Market Identifier Code (MIC) is an international standard, which \"specifies a universal method of identifying exchanges, trading platforms, regulated or non-regulated markets and trade reporting facilities as sources of prices and related information in order to facilitate automated processing\" as quoted from its official site . The U.S. Equities market has 13 lit exchanges and dozens of Alternative Trading Systems (ATSs), a.k.a. dark pools. Many buy side firms also operate their own non-ATS crossing systems.","title":"Introduction"},{"location":"2020/2020.03.23/#question","text":"There might be multiple exchanges quoting at the National Best Bid and Offer (NBBO) price level at any given time. It is assumed that child orders are always placed at NBBO and can be placed to any lit exchanges. The below function simChildOrders simulates some BUY orders with execution destination ( exDest ). See the definition of FIX tag for exDest . It also has a column nbbExchanges , which shows the list of lit exchanges that are present at the best bid price level. simChildOrders:{[nOrders] seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exDest:nOrders?litVenues; system \"S \",string seed; nExchanges:3+nOrders?(count litVenues)-3; system \"S \",string seed; nbbVenues:{y?x}[litVenues;] each nExchanges; ([] time:submitTimes;side:`BUY;exDest:exDest;nbbVenues:nbbVenues) }; childOrders:simChildOrders[5000]; Find the number of orders which are placed to exchanges present at NBB (National Best Bid).","title":"Question"},{"location":"2020/2020.03.23/#answer","text":"","title":"Answer"},{"location":"2020/2020.03.23/#use-each-both","text":"Learn more about each or each both here . exec sum in'[exDest;nbbVenues] from childOrders Each applied to a binary value is also called each both and the infix form can be used. exec sum exDest in' nbbVenues from childOrders","title":"Use each both"},{"location":"2020/2020.03.23/#use-where-and-any","text":"exec count i from childOrders where any each exDest=nbbVenues","title":"Use where and any"},{"location":"2020/2020.03.23/#use-list-argument","text":"Note that the anonymous function is unary and the parameter is a list. exec sum {x[0] in x[1]} each flip (exDest;nbbVenues) from childOrders","title":"Use list argument"},{"location":"2020/2020.03.23/#use-operator-apply","text":"The operator apply . applies a function to a list and use the individual list elements as the arguments to the function. This is very much similar to * operator to unpack argument list to function call in Python and the spread operator ... in JavaScript . exec sum ({x in y}.) each flip (exDest;nbbVenues) from childOrders","title":"Use operator apply ."},{"location":"2020/2020.03.23a/","text":"Answer \u00b6 Use each both \u00b6 Learn more about each or each both here . exec sum in'[exDest;nbbVenues] from childOrders Each applied to a binary value is also called each both and the infix form can be used. exec sum exDest in' nbbVenues from childOrders Use where and any \u00b6 exec count i from childOrders where any each exDest=nbbVenues Use list argument \u00b6 Note that the anonymous function is unary and the parameter is a list. exec sum {x[0] in x[1]} each flip (exDest;nbbVenues) from childOrders Use operator apply . \u00b6 The operator apply . applies a function to a list and use the individual list elements as the arguments to the function. This is very much similar to * operator to unpack argument list to function call in Python and the spread operator ... in JavaScript . exec sum ({x in y}.) each flip (exDest;nbbVenues) from childOrders","title":"2020.03.23a"},{"location":"2020/2020.03.23a/#answer","text":"","title":"Answer"},{"location":"2020/2020.03.23a/#use-each-both","text":"Learn more about each or each both here . exec sum in'[exDest;nbbVenues] from childOrders Each applied to a binary value is also called each both and the infix form can be used. exec sum exDest in' nbbVenues from childOrders","title":"Use each both"},{"location":"2020/2020.03.23a/#use-where-and-any","text":"exec count i from childOrders where any each exDest=nbbVenues","title":"Use where and any"},{"location":"2020/2020.03.23a/#use-list-argument","text":"Note that the anonymous function is unary and the parameter is a list. exec sum {x[0] in x[1]} each flip (exDest;nbbVenues) from childOrders","title":"Use list argument"},{"location":"2020/2020.03.23a/#use-operator-apply","text":"The operator apply . applies a function to a list and use the individual list elements as the arguments to the function. This is very much similar to * operator to unpack argument list to function call in Python and the spread operator ... in JavaScript . exec sum ({x in y}.) each flip (exDest;nbbVenues) from childOrders","title":"Use operator apply ."},{"location":"2020/2020.03.23q/","text":"Source: adopted from here Introduction \u00b6 Market Identifier Code (MIC) is an international standard, which \"specifies a universal method of identifying exchanges, trading platforms, regulated or non-regulated markets and trade reporting facilities as sources of prices and related information in order to facilitate automated processing\" as quoted from its official site . The U.S. Equities market has 13 lit exchanges and dozens of Alternative Trading Systems (ATSs), a.k.a. dark pools. Many buy side firms also operate their own non-ATS crossing systems. Question \u00b6 There might be multiple exchanges quoting at the National Best Bid and Offer (NBBO) price level at any given time. It is assumed that child orders are always placed at NBBO and can be placed to any lit exchanges. The below function simChildOrders simulates some BUY orders with execution destination ( exDest ). See the definition of FIX tag for exDest . It also has a column nbbExchanges , which shows the list of lit exchanges that are present at the best bid price level. simChildOrders:{[nOrders] seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exDest:nOrders?litVenues; system \"S \",string seed; nExchanges:3+nOrders?(count litVenues)-3; system \"S \",string seed; nbbVenues:{y?x}[litVenues;] each nExchanges; ([] time:submitTimes;side:`BUY;exDest:exDest;nbbVenues:nbbVenues) }; childOrders:simChildOrders[5000]; Find the number of orders which are placed to exchanges present at NBB (National Best Bid).","title":"2020.03.23q"},{"location":"2020/2020.03.23q/#introduction","text":"Market Identifier Code (MIC) is an international standard, which \"specifies a universal method of identifying exchanges, trading platforms, regulated or non-regulated markets and trade reporting facilities as sources of prices and related information in order to facilitate automated processing\" as quoted from its official site . The U.S. Equities market has 13 lit exchanges and dozens of Alternative Trading Systems (ATSs), a.k.a. dark pools. Many buy side firms also operate their own non-ATS crossing systems.","title":"Introduction"},{"location":"2020/2020.03.23q/#question","text":"There might be multiple exchanges quoting at the National Best Bid and Offer (NBBO) price level at any given time. It is assumed that child orders are always placed at NBBO and can be placed to any lit exchanges. The below function simChildOrders simulates some BUY orders with execution destination ( exDest ). See the definition of FIX tag for exDest . It also has a column nbbExchanges , which shows the list of lit exchanges that are present at the best bid price level. simChildOrders:{[nOrders] seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; submitTimes:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; exDest:nOrders?litVenues; system \"S \",string seed; nExchanges:3+nOrders?(count litVenues)-3; system \"S \",string seed; nbbVenues:{y?x}[litVenues;] each nExchanges; ([] time:submitTimes;side:`BUY;exDest:exDest;nbbVenues:nbbVenues) }; childOrders:simChildOrders[5000]; Find the number of orders which are placed to exchanges present at NBB (National Best Bid).","title":"Question"},{"location":"2020/2020.03.30/","text":"Source: adopted from here Introduction \u00b6 The U.S. Equities market has 13 lit exchanges and each exchange reports its top of book information to SIP (Securities Information Processor), which then publishes the NBBO (National Best Bid and Offer) to the public to consume. Many institutional users can also subscribe the direct feed from each exchange and build their own limit order book. The advantages of this approach are: it has smaller latency direct feed contains multiple price levels of the limit order book it includes odd-lot quotes Question \u00b6 To make the illustration easier, an excerpt of the consolidated limit order book is simulated as follows: simQuote:{[venueList;nRow] priceList:30+0.01*til 10; prices:asc -3?priceList; venues:3?venueList; bidPrices:(count each venues)#'prices; bidExchanges:raze venues; (bidPrices;bidExchanges) }; simLob:{ nRows:20; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; times:asc closeTime&openTime+nRows?390*60*1000; nExchanges:2+nRows?(count litVenues)-8; bidVenues:{y?x}[litVenues;] each nExchanges; quotes:simQuote[bidVenues;] each til nRows; :([]time:times;bidPrices:raze each quotes[;0];bidExchanges:quotes[;1]); }; lob:simLob[]; The simulated data has three columns: time : This is the timestamp of the limit order book snapshot. bidPrices : It presents the multiple price levels on the buy side of the limit order book. Note that multiple exchange might quote at the same price level. The bid prices is already sorted descendingly. bidExchanges : This columns corresponds to each values from bidPrices and show which exchange each bid price comes from. So bidExchanges and bidPrices have the same length element wise. Find bid book on XNYS , i.e. New York Stock Exchange. Answer \u00b6 The first line finds the location where XNYS is present and the second line for the corresponding bid prices for XNYS . Note the use of each both in this question and the same technique is used in the question from the previous week. lob:update nyseLoc:(where') `XNYS=bidExchanges from lob; select time, bidPrices:bidPrices@' nyseLoc from lob If you are a one liner, you can also do the following: select time, bidPrices:bidPrices@' (where') `XNYS=bidExchanges from lob","title":"2020.03.30"},{"location":"2020/2020.03.30/#introduction","text":"The U.S. Equities market has 13 lit exchanges and each exchange reports its top of book information to SIP (Securities Information Processor), which then publishes the NBBO (National Best Bid and Offer) to the public to consume. Many institutional users can also subscribe the direct feed from each exchange and build their own limit order book. The advantages of this approach are: it has smaller latency direct feed contains multiple price levels of the limit order book it includes odd-lot quotes","title":"Introduction"},{"location":"2020/2020.03.30/#question","text":"To make the illustration easier, an excerpt of the consolidated limit order book is simulated as follows: simQuote:{[venueList;nRow] priceList:30+0.01*til 10; prices:asc -3?priceList; venues:3?venueList; bidPrices:(count each venues)#'prices; bidExchanges:raze venues; (bidPrices;bidExchanges) }; simLob:{ nRows:20; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; times:asc closeTime&openTime+nRows?390*60*1000; nExchanges:2+nRows?(count litVenues)-8; bidVenues:{y?x}[litVenues;] each nExchanges; quotes:simQuote[bidVenues;] each til nRows; :([]time:times;bidPrices:raze each quotes[;0];bidExchanges:quotes[;1]); }; lob:simLob[]; The simulated data has three columns: time : This is the timestamp of the limit order book snapshot. bidPrices : It presents the multiple price levels on the buy side of the limit order book. Note that multiple exchange might quote at the same price level. The bid prices is already sorted descendingly. bidExchanges : This columns corresponds to each values from bidPrices and show which exchange each bid price comes from. So bidExchanges and bidPrices have the same length element wise. Find bid book on XNYS , i.e. New York Stock Exchange.","title":"Question"},{"location":"2020/2020.03.30/#answer","text":"The first line finds the location where XNYS is present and the second line for the corresponding bid prices for XNYS . Note the use of each both in this question and the same technique is used in the question from the previous week. lob:update nyseLoc:(where') `XNYS=bidExchanges from lob; select time, bidPrices:bidPrices@' nyseLoc from lob If you are a one liner, you can also do the following: select time, bidPrices:bidPrices@' (where') `XNYS=bidExchanges from lob","title":"Answer"},{"location":"2020/2020.03.30a/","text":"Answer \u00b6 The first line finds the location where XNYS is present and the second line for the corresponding bid prices for XNYS . Note the use of each both in this question and the same technique is used in the question from the previous week. lob:update nyseLoc:(where') `XNYS=bidExchanges from lob; select time, bidPrices:bidPrices@' nyseLoc from lob If you are a one liner, you can also do the following: select time, bidPrices:bidPrices@' (where') `XNYS=bidExchanges from lob","title":"2020.03.30a"},{"location":"2020/2020.03.30a/#answer","text":"The first line finds the location where XNYS is present and the second line for the corresponding bid prices for XNYS . Note the use of each both in this question and the same technique is used in the question from the previous week. lob:update nyseLoc:(where') `XNYS=bidExchanges from lob; select time, bidPrices:bidPrices@' nyseLoc from lob If you are a one liner, you can also do the following: select time, bidPrices:bidPrices@' (where') `XNYS=bidExchanges from lob","title":"Answer"},{"location":"2020/2020.03.30q/","text":"Source: adopted from here Introduction \u00b6 The U.S. Equities market has 13 lit exchanges and each exchange reports its top of book information to SIP (Securities Information Processor), which then publishes the NBBO (National Best Bid and Offer) to the public to consume. Many institutional users can also subscribe the direct feed from each exchange and build their own limit order book. The advantages of this approach are: it has smaller latency direct feed contains multiple price levels of the limit order book it includes odd-lot quotes Question \u00b6 To make the illustration easier, an excerpt of the consolidated limit order book is simulated as follows: simQuote:{[venueList;nRow] priceList:30+0.01*til 10; prices:asc -3?priceList; venues:3?venueList; bidPrices:(count each venues)#'prices; bidExchanges:raze venues; (bidPrices;bidExchanges) }; simLob:{ nRows:20; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; times:asc closeTime&openTime+nRows?390*60*1000; nExchanges:2+nRows?(count litVenues)-8; bidVenues:{y?x}[litVenues;] each nExchanges; quotes:simQuote[bidVenues;] each til nRows; :([]time:times;bidPrices:raze each quotes[;0];bidExchanges:quotes[;1]); }; lob:simLob[]; The simulated data has three columns: time : This is the timestamp of the limit order book snapshot. bidPrices : It presents the multiple price levels on the buy side of the limit order book. Note that multiple exchange might quote at the same price level. The bid prices is already sorted descendingly. bidExchanges : This columns corresponds to each values from bidPrices and show which exchange each bid price comes from. So bidExchanges and bidPrices have the same length element wise. Find bid book on XNYS , i.e. New York Stock Exchange.","title":"2020.03.30q"},{"location":"2020/2020.03.30q/#introduction","text":"The U.S. Equities market has 13 lit exchanges and each exchange reports its top of book information to SIP (Securities Information Processor), which then publishes the NBBO (National Best Bid and Offer) to the public to consume. Many institutional users can also subscribe the direct feed from each exchange and build their own limit order book. The advantages of this approach are: it has smaller latency direct feed contains multiple price levels of the limit order book it includes odd-lot quotes","title":"Introduction"},{"location":"2020/2020.03.30q/#question","text":"To make the illustration easier, an excerpt of the consolidated limit order book is simulated as follows: simQuote:{[venueList;nRow] priceList:30+0.01*til 10; prices:asc -3?priceList; venues:3?venueList; bidPrices:(count each venues)#'prices; bidExchanges:raze venues; (bidPrices;bidExchanges) }; simLob:{ nRows:20; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; litVenues:`XNYS`ARCX`XCHI`XASE`XCIS`XNAS`XBOS`XPHL`BATS`BATY`EDGA`EDGX`IEXG; system \"S \",string seed; times:asc closeTime&openTime+nRows?390*60*1000; nExchanges:2+nRows?(count litVenues)-8; bidVenues:{y?x}[litVenues;] each nExchanges; quotes:simQuote[bidVenues;] each til nRows; :([]time:times;bidPrices:raze each quotes[;0];bidExchanges:quotes[;1]); }; lob:simLob[]; The simulated data has three columns: time : This is the timestamp of the limit order book snapshot. bidPrices : It presents the multiple price levels on the buy side of the limit order book. Note that multiple exchange might quote at the same price level. The bid prices is already sorted descendingly. bidExchanges : This columns corresponds to each values from bidPrices and show which exchange each bid price comes from. So bidExchanges and bidPrices have the same length element wise. Find bid book on XNYS , i.e. New York Stock Exchange.","title":"Question"},{"location":"2020/2020.04.06/","text":"Source: adopted from here Introduction \u00b6 Time in force ( TIF ) is a special instruction to indicate how long an order will remain live before it is executed, cancelled or expires. As a result, it gives the trader or the electronic algorithm a mechanism of controlling time for an order. A few selected TIF values include: Day Good Till Cancel ( GTC ) At the Opening ( OPG ) Immediate Or Cancel ( IOC ) At the Close ( CLS ) The FIX tag for time in force is 59 and additional details are available here . Question \u00b6 In algorithmic trading, a Smart Order Router (SOR) creates child orders and sends them to different exchanges for execution and each child order has an attribute called tif . The function simOrdersTIF simulates a list of child orders with two attributes: time for order creation time and tif for the order's time in force. simOrdersTIF:{ nOrders:10000; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; listTifs:`Day,20#`IOC; system \"S \",string seed; times:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; tifs:nOrders?listTifs; ([] time:times;tif:tifs) }; orders:simOrdersTIF[]; Find all clusters of IOC orders and the cluster with the longest duration. A cluster of IOC orders is defined as a group of IOC orders created in a row. A cluster's duration is the time difference between the first order and the last order within a cluster. Answer \u00b6 The following code snippet is suggested. I intentionally break it into multiple lines to make the explanations easier. iocClusters:select time,tif,isIOC:`IOC=tif from orders; iocClusters:update iocGroup:sums 1_(>)prior (0,isIOC) from iocClusters; iocClusters:update duration:last time-first time by iocGroup from iocClusters where isIOC; select from iocClusters where duration=max duration Some explanations: Line 1 updates the table with a boolean flag to indicate whether an order is an IOC order. Line 2 creates an IOC group for each IOC cluster. The snippet 1_(>)prior (0,isIOC) flags the first IOC order in an IOC cluster. The sums simply creates an increasing group index for each IOC cluster. Line 3 finds the time duration of each IOC clusters. Line 4 gives the IOC clusters with maximal duration.","title":"2020.04.06"},{"location":"2020/2020.04.06/#introduction","text":"Time in force ( TIF ) is a special instruction to indicate how long an order will remain live before it is executed, cancelled or expires. As a result, it gives the trader or the electronic algorithm a mechanism of controlling time for an order. A few selected TIF values include: Day Good Till Cancel ( GTC ) At the Opening ( OPG ) Immediate Or Cancel ( IOC ) At the Close ( CLS ) The FIX tag for time in force is 59 and additional details are available here .","title":"Introduction"},{"location":"2020/2020.04.06/#question","text":"In algorithmic trading, a Smart Order Router (SOR) creates child orders and sends them to different exchanges for execution and each child order has an attribute called tif . The function simOrdersTIF simulates a list of child orders with two attributes: time for order creation time and tif for the order's time in force. simOrdersTIF:{ nOrders:10000; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; listTifs:`Day,20#`IOC; system \"S \",string seed; times:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; tifs:nOrders?listTifs; ([] time:times;tif:tifs) }; orders:simOrdersTIF[]; Find all clusters of IOC orders and the cluster with the longest duration. A cluster of IOC orders is defined as a group of IOC orders created in a row. A cluster's duration is the time difference between the first order and the last order within a cluster.","title":"Question"},{"location":"2020/2020.04.06/#answer","text":"The following code snippet is suggested. I intentionally break it into multiple lines to make the explanations easier. iocClusters:select time,tif,isIOC:`IOC=tif from orders; iocClusters:update iocGroup:sums 1_(>)prior (0,isIOC) from iocClusters; iocClusters:update duration:last time-first time by iocGroup from iocClusters where isIOC; select from iocClusters where duration=max duration Some explanations: Line 1 updates the table with a boolean flag to indicate whether an order is an IOC order. Line 2 creates an IOC group for each IOC cluster. The snippet 1_(>)prior (0,isIOC) flags the first IOC order in an IOC cluster. The sums simply creates an increasing group index for each IOC cluster. Line 3 finds the time duration of each IOC clusters. Line 4 gives the IOC clusters with maximal duration.","title":"Answer"},{"location":"2020/2020.04.06a/","text":"Answer \u00b6 The following code snippet is suggested. I intentionally break it into multiple lines to make the explanations easier. iocClusters:select time,tif,isIOC:`IOC=tif from orders; iocClusters:update iocGroup:sums 1_(>)prior (0,isIOC) from iocClusters; iocClusters:update duration:last time-first time by iocGroup from iocClusters where isIOC; select from iocClusters where duration=max duration Some explanations: Line 1 updates the table with a boolean flag to indicate whether an order is an IOC order. Line 2 creates an IOC group for each IOC cluster. The snippet 1_(>)prior (0,isIOC) flags the first IOC order in an IOC cluster. The sums simply creates an increasing group index for each IOC cluster. Line 3 finds the time duration of each IOC clusters. Line 4 gives the IOC clusters with maximal duration.","title":"2020.04.06a"},{"location":"2020/2020.04.06a/#answer","text":"The following code snippet is suggested. I intentionally break it into multiple lines to make the explanations easier. iocClusters:select time,tif,isIOC:`IOC=tif from orders; iocClusters:update iocGroup:sums 1_(>)prior (0,isIOC) from iocClusters; iocClusters:update duration:last time-first time by iocGroup from iocClusters where isIOC; select from iocClusters where duration=max duration Some explanations: Line 1 updates the table with a boolean flag to indicate whether an order is an IOC order. Line 2 creates an IOC group for each IOC cluster. The snippet 1_(>)prior (0,isIOC) flags the first IOC order in an IOC cluster. The sums simply creates an increasing group index for each IOC cluster. Line 3 finds the time duration of each IOC clusters. Line 4 gives the IOC clusters with maximal duration.","title":"Answer"},{"location":"2020/2020.04.06q/","text":"Source: adopted from here Introduction \u00b6 Time in force ( TIF ) is a special instruction to indicate how long an order will remain live before it is executed, cancelled or expires. As a result, it gives the trader or the electronic algorithm a mechanism of controlling time for an order. A few selected TIF values include: Day Good Till Cancel ( GTC ) At the Opening ( OPG ) Immediate Or Cancel ( IOC ) At the Close ( CLS ) The FIX tag for time in force is 59 and additional details are available here . Question \u00b6 In algorithmic trading, a Smart Order Router (SOR) creates child orders and sends them to different exchanges for execution and each child order has an attribute called tif . The function simOrdersTIF simulates a list of child orders with two attributes: time for order creation time and tif for the order's time in force. simOrdersTIF:{ nOrders:10000; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; listTifs:`Day,20#`IOC; system \"S \",string seed; times:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; tifs:nOrders?listTifs; ([] time:times;tif:tifs) }; orders:simOrdersTIF[]; Find all clusters of IOC orders and the cluster with the longest duration. A cluster of IOC orders is defined as a group of IOC orders created in a row. A cluster's duration is the time difference between the first order and the last order within a cluster.","title":"2020.04.06q"},{"location":"2020/2020.04.06q/#introduction","text":"Time in force ( TIF ) is a special instruction to indicate how long an order will remain live before it is executed, cancelled or expires. As a result, it gives the trader or the electronic algorithm a mechanism of controlling time for an order. A few selected TIF values include: Day Good Till Cancel ( GTC ) At the Opening ( OPG ) Immediate Or Cancel ( IOC ) At the Close ( CLS ) The FIX tag for time in force is 59 and additional details are available here .","title":"Introduction"},{"location":"2020/2020.04.06q/#question","text":"In algorithmic trading, a Smart Order Router (SOR) creates child orders and sends them to different exchanges for execution and each child order has an attribute called tif . The function simOrdersTIF simulates a list of child orders with two attributes: time for order creation time and tif for the order's time in force. simOrdersTIF:{ nOrders:10000; seed:-314159; openTime:`time$09:30; closeTime:`time$16:00; listTifs:`Day,20#`IOC; system \"S \",string seed; times:asc closeTime&openTime+nOrders?390*60*1000; system \"S \",string seed; tifs:nOrders?listTifs; ([] time:times;tif:tifs) }; orders:simOrdersTIF[]; Find all clusters of IOC orders and the cluster with the longest duration. A cluster of IOC orders is defined as a group of IOC orders created in a row. A cluster's duration is the time difference between the first order and the last order within a cluster.","title":"Question"},{"location":"2020/2020.04.13/","text":"Source: adopted from here Introduction \u00b6 The question from last week mentions that time in force is tag 59 in FIX Protocol. The Financial Information eXchange (FIX) protocol is an electronic communication protocol widely used by today's financial trading systems and trading algorithms. Both order management system (OMS) and execution management system (EMS) use FIX to communicate order/execution information to different components electronically. All these incoming or outgoing FIX messages are logged with a key/value format. For example, the following log snippet 35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS might result from creating a new order sent to NYSE to buy 200 shares of Morgan Stanley at price 33.85. A good source of information on FIX message is FIXimate . Question \u00b6 Write a function parseFixMsg to parse FIX message. This function returns a dictionary with tag number/value as the key/value of the dictionary. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg[fixMsg] Answer \u00b6 Here is the simple solution. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg:{[msg](!).\"S=|\"0:msg}; parseFixMsg fixMsg An acute reader might notice that the dictionary values are a string. To cast the values to proper types, some further work is required. Fortunately a nice solution is provided by one of Kx Systems' white papers. For more details, read the comprehensive article on parsing FIX messages in Kdb+ and FIX messaging .","title":"2020.04.13"},{"location":"2020/2020.04.13/#introduction","text":"The question from last week mentions that time in force is tag 59 in FIX Protocol. The Financial Information eXchange (FIX) protocol is an electronic communication protocol widely used by today's financial trading systems and trading algorithms. Both order management system (OMS) and execution management system (EMS) use FIX to communicate order/execution information to different components electronically. All these incoming or outgoing FIX messages are logged with a key/value format. For example, the following log snippet 35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS might result from creating a new order sent to NYSE to buy 200 shares of Morgan Stanley at price 33.85. A good source of information on FIX message is FIXimate .","title":"Introduction"},{"location":"2020/2020.04.13/#question","text":"Write a function parseFixMsg to parse FIX message. This function returns a dictionary with tag number/value as the key/value of the dictionary. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg[fixMsg]","title":"Question"},{"location":"2020/2020.04.13/#answer","text":"Here is the simple solution. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg:{[msg](!).\"S=|\"0:msg}; parseFixMsg fixMsg An acute reader might notice that the dictionary values are a string. To cast the values to proper types, some further work is required. Fortunately a nice solution is provided by one of Kx Systems' white papers. For more details, read the comprehensive article on parsing FIX messages in Kdb+ and FIX messaging .","title":"Answer"},{"location":"2020/2020.04.13a/","text":"Answer \u00b6 Here is the simple solution. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg:{[msg](!).\"S=|\"0:msg}; parseFixMsg fixMsg An acute reader might notice that the dictionary values are a string. To cast the values to proper types, some further work is required. Fortunately a nice solution is provided by one of Kx Systems' white papers. For more details, read the comprehensive article on parsing FIX messages in Kdb+ and FIX messaging .","title":"2020.04.13a"},{"location":"2020/2020.04.13a/#answer","text":"Here is the simple solution. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg:{[msg](!).\"S=|\"0:msg}; parseFixMsg fixMsg An acute reader might notice that the dictionary values are a string. To cast the values to proper types, some further work is required. Fortunately a nice solution is provided by one of Kx Systems' white papers. For more details, read the comprehensive article on parsing FIX messages in Kdb+ and FIX messaging .","title":"Answer"},{"location":"2020/2020.04.13q/","text":"Source: adopted from here Introduction \u00b6 The question from last week mentions that time in force is tag 59 in FIX Protocol. The Financial Information eXchange (FIX) protocol is an electronic communication protocol widely used by today's financial trading systems and trading algorithms. Both order management system (OMS) and execution management system (EMS) use FIX to communicate order/execution information to different components electronically. All these incoming or outgoing FIX messages are logged with a key/value format. For example, the following log snippet 35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS might result from creating a new order sent to NYSE to buy 200 shares of Morgan Stanley at price 33.85. A good source of information on FIX message is FIXimate . Question \u00b6 Write a function parseFixMsg to parse FIX message. This function returns a dictionary with tag number/value as the key/value of the dictionary. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg[fixMsg]","title":"2020.04.13q"},{"location":"2020/2020.04.13q/#introduction","text":"The question from last week mentions that time in force is tag 59 in FIX Protocol. The Financial Information eXchange (FIX) protocol is an electronic communication protocol widely used by today's financial trading systems and trading algorithms. Both order management system (OMS) and execution management system (EMS) use FIX to communicate order/execution information to different components electronically. All these incoming or outgoing FIX messages are logged with a key/value format. For example, the following log snippet 35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS might result from creating a new order sent to NYSE to buy 200 shares of Morgan Stanley at price 33.85. A good source of information on FIX message is FIXimate .","title":"Introduction"},{"location":"2020/2020.04.13q/#question","text":"Write a function parseFixMsg to parse FIX message. This function returns a dictionary with tag number/value as the key/value of the dictionary. fixMsg:\"35=D|22=RIC|48=MS.N|54=1|44=33.85|53=500|30=XNYS\"; parseFixMsg[fixMsg]","title":"Question"},{"location":"2020/2020.04.20/","text":"Source: adopted from here Introduction \u00b6 March 2020 is definitely unprecedented in the history of financial markets. Both market volume and volatility heightened during this 2020 stock market crash . The market wide circuit breaker was triggered four times in 10 days (Mar 9, 12, 16 and 18) and thousands of individual stocks had circuit breaker activated. There is no respite in sight for this volatility. The Limit Up Limit Down (LULD) was designed to replace the single stock circuit breaker. A stock enters a Limit State if its price deviation from previous close exceeds a certain percentage, which depends on the price of the stock. For Tier 1 securities, the threshold percentage from market open auction to 3:35pm is as follows: Price Range Price Band Percentage strictly greater than 3.0 5% [0.75, 3.0] inclusive on both side 20% strictly less than 0.75 The lesser of $0.15 and 75% For more details about LULD, see Nasdaq LULD FAQ . Question \u00b6 Write a q function calculateLULD to calculate the LULD prices for a single price or list of prices. This function returns a list and each element of the list is a two-element list which has first element as the limit up price and the second element as the limit down price. For example, calculateLULD 3 / enlist 3.6 2.4 calculateLULD 3 10 / (3.6 2.4;10.5 9.5) calculateLULD 0.1 0.5 3 10 / (0.175 0.025;0.65 0.35;3.6 2.4;10.5 9.5) Answer \u00b6 Below is one suggested implementation to calculate the limit up limit down prices for Tier 1 securities in the opening auction period and the continuous session up to 15:35 in the U.S. equities market. calculateLULD:{ / Makes sure input is a list of float price:\"f\"$(),x; / Defines percentage bands bandPctCutoff:0.75 0.2 0.05; / Defines the lower bound price of each price band lowerBound:0.15 0w 0w; / Finds the percentage band bucket which each price falls into / Note that 0.74999 is used, instead of 0.75 loc:0.749999 3f binr price; / Finds the price bands for the given list of prices priceBand:lowerBound[loc]&price*bandPctCutoff loc; / Applies the price bands to the given list of prices flip (price+priceBand;price-priceBand) }; My friend Alvi Kabir provides the following creative solution, which uses the fact that the sorted attribute (`s#) when applied to a dictionary makes the dictionary into a step function. See some official document here . I like a lot the way he handles the case when price is between $0.2 and $0.75. calculateLULD:{ d:`s#0 .2 .75 3.0001!(.75;0n;.2;.05); p:.15^x*d \"f\"$(),x; flip (x+p;x-p) };","title":"2020.04.20"},{"location":"2020/2020.04.20/#introduction","text":"March 2020 is definitely unprecedented in the history of financial markets. Both market volume and volatility heightened during this 2020 stock market crash . The market wide circuit breaker was triggered four times in 10 days (Mar 9, 12, 16 and 18) and thousands of individual stocks had circuit breaker activated. There is no respite in sight for this volatility. The Limit Up Limit Down (LULD) was designed to replace the single stock circuit breaker. A stock enters a Limit State if its price deviation from previous close exceeds a certain percentage, which depends on the price of the stock. For Tier 1 securities, the threshold percentage from market open auction to 3:35pm is as follows: Price Range Price Band Percentage strictly greater than 3.0 5% [0.75, 3.0] inclusive on both side 20% strictly less than 0.75 The lesser of $0.15 and 75% For more details about LULD, see Nasdaq LULD FAQ .","title":"Introduction"},{"location":"2020/2020.04.20/#question","text":"Write a q function calculateLULD to calculate the LULD prices for a single price or list of prices. This function returns a list and each element of the list is a two-element list which has first element as the limit up price and the second element as the limit down price. For example, calculateLULD 3 / enlist 3.6 2.4 calculateLULD 3 10 / (3.6 2.4;10.5 9.5) calculateLULD 0.1 0.5 3 10 / (0.175 0.025;0.65 0.35;3.6 2.4;10.5 9.5)","title":"Question"},{"location":"2020/2020.04.20/#answer","text":"Below is one suggested implementation to calculate the limit up limit down prices for Tier 1 securities in the opening auction period and the continuous session up to 15:35 in the U.S. equities market. calculateLULD:{ / Makes sure input is a list of float price:\"f\"$(),x; / Defines percentage bands bandPctCutoff:0.75 0.2 0.05; / Defines the lower bound price of each price band lowerBound:0.15 0w 0w; / Finds the percentage band bucket which each price falls into / Note that 0.74999 is used, instead of 0.75 loc:0.749999 3f binr price; / Finds the price bands for the given list of prices priceBand:lowerBound[loc]&price*bandPctCutoff loc; / Applies the price bands to the given list of prices flip (price+priceBand;price-priceBand) }; My friend Alvi Kabir provides the following creative solution, which uses the fact that the sorted attribute (`s#) when applied to a dictionary makes the dictionary into a step function. See some official document here . I like a lot the way he handles the case when price is between $0.2 and $0.75. calculateLULD:{ d:`s#0 .2 .75 3.0001!(.75;0n;.2;.05); p:.15^x*d \"f\"$(),x; flip (x+p;x-p) };","title":"Answer"},{"location":"2020/2020.04.20a/","text":"Answer \u00b6 Below is one suggested implementation to calculate the limit up limit down prices for Tier 1 securities in the opening auction period and the continuous session up to 15:35 in the U.S. equities market. calculateLULD:{ / Makes sure input is a list of float price:\"f\"$(),x; / Defines percentage bands bandPctCutoff:0.75 0.2 0.05; / Defines the lower bound price of each price band lowerBound:0.15 0w 0w; / Finds the percentage band bucket which each price falls into / Note that 0.74999 is used, instead of 0.75 loc:0.749999 3f binr price; / Finds the price bands for the given list of prices priceBand:lowerBound[loc]&price*bandPctCutoff loc; / Applies the price bands to the given list of prices flip (price+priceBand;price-priceBand) }; My friend Alvi Kabir provides the following creative solution, which uses the fact that the sorted attribute (`s#) when applied to a dictionary makes the dictionary into a step function. See some official document here . I like a lot the way he handles the case when price is between $0.2 and $0.75. calculateLULD:{ d:`s#0 .2 .75 3.0001!(.75;0n;.2;.05); p:.15^x*d \"f\"$(),x; flip (x+p;x-p) };","title":"2020.04.20a"},{"location":"2020/2020.04.20a/#answer","text":"Below is one suggested implementation to calculate the limit up limit down prices for Tier 1 securities in the opening auction period and the continuous session up to 15:35 in the U.S. equities market. calculateLULD:{ / Makes sure input is a list of float price:\"f\"$(),x; / Defines percentage bands bandPctCutoff:0.75 0.2 0.05; / Defines the lower bound price of each price band lowerBound:0.15 0w 0w; / Finds the percentage band bucket which each price falls into / Note that 0.74999 is used, instead of 0.75 loc:0.749999 3f binr price; / Finds the price bands for the given list of prices priceBand:lowerBound[loc]&price*bandPctCutoff loc; / Applies the price bands to the given list of prices flip (price+priceBand;price-priceBand) }; My friend Alvi Kabir provides the following creative solution, which uses the fact that the sorted attribute (`s#) when applied to a dictionary makes the dictionary into a step function. See some official document here . I like a lot the way he handles the case when price is between $0.2 and $0.75. calculateLULD:{ d:`s#0 .2 .75 3.0001!(.75;0n;.2;.05); p:.15^x*d \"f\"$(),x; flip (x+p;x-p) };","title":"Answer"},{"location":"2020/2020.04.20q/","text":"Source: adopted from here Introduction \u00b6 March 2020 is definitely unprecedented in the history of financial markets. Both market volume and volatility heightened during this 2020 stock market crash . The market wide circuit breaker was triggered four times in 10 days (Mar 9, 12, 16 and 18) and thousands of individual stocks had circuit breaker activated. There is no respite in sight for this volatility. The Limit Up Limit Down (LULD) was designed to replace the single stock circuit breaker. A stock enters a Limit State if its price deviation from previous close exceeds a certain percentage, which depends on the price of the stock. For Tier 1 securities, the threshold percentage from market open auction to 3:35pm is as follows: Price Range Price Band Percentage strictly greater than 3.0 5% [0.75, 3.0] inclusive on both side 20% strictly less than 0.75 The lesser of $0.15 and 75% For more details about LULD, see Nasdaq LULD FAQ . Question \u00b6 Write a q function calculateLULD to calculate the LULD prices for a single price or list of prices. This function returns a list and each element of the list is a two-element list which has first element as the limit up price and the second element as the limit down price. For example, calculateLULD 3 / enlist 3.6 2.4 calculateLULD 3 10 / (3.6 2.4;10.5 9.5) calculateLULD 0.1 0.5 3 10 / (0.175 0.025;0.65 0.35;3.6 2.4;10.5 9.5)","title":"2020.04.20q"},{"location":"2020/2020.04.20q/#introduction","text":"March 2020 is definitely unprecedented in the history of financial markets. Both market volume and volatility heightened during this 2020 stock market crash . The market wide circuit breaker was triggered four times in 10 days (Mar 9, 12, 16 and 18) and thousands of individual stocks had circuit breaker activated. There is no respite in sight for this volatility. The Limit Up Limit Down (LULD) was designed to replace the single stock circuit breaker. A stock enters a Limit State if its price deviation from previous close exceeds a certain percentage, which depends on the price of the stock. For Tier 1 securities, the threshold percentage from market open auction to 3:35pm is as follows: Price Range Price Band Percentage strictly greater than 3.0 5% [0.75, 3.0] inclusive on both side 20% strictly less than 0.75 The lesser of $0.15 and 75% For more details about LULD, see Nasdaq LULD FAQ .","title":"Introduction"},{"location":"2020/2020.04.20q/#question","text":"Write a q function calculateLULD to calculate the LULD prices for a single price or list of prices. This function returns a list and each element of the list is a two-element list which has first element as the limit up price and the second element as the limit down price. For example, calculateLULD 3 / enlist 3.6 2.4 calculateLULD 3 10 / (3.6 2.4;10.5 9.5) calculateLULD 0.1 0.5 3 10 / (0.175 0.025;0.65 0.35;3.6 2.4;10.5 9.5)","title":"Question"},{"location":"2020/2020.04.27/","text":"Source: adopted from here Introduction \u00b6 To gauge the effect of an event on market measures like volume and volatility, one simple way is to compare the measures before and after the event. To make a fair comparison, it makes sense to use the same number of trading days in the before and after data sample periods. One of such events is stock split or reverse split. The most common split ratios are 2-for-1, which means that the stockholder will have two for every share held earlier. Reverse stock splits are the opposite transaction, where a company divides, instead of multiplies, the number of shares that stockholders own, raising the market price accordingly. Three key pieces of information about a stock split is: symbol: the trading identifier of the stock date: the effective date of the split split ratio: how many new shares one existing share is converted to Question \u00b6 The function getSplitEvents simulates the stock split events which contain the trading identifier ( sym ), effective date ( date ) and the split ratio ( splitRatio ). The function getDailyVolume simulates the daily volume around the stock split effective date. getSplitEvents:{ ([]sym:`ABC`DEF;date:2020.04.08 2020.04.13;splitRatio:0.2 10) }; getDailyVolume:{ dates:2020.03.10+til 50; weekdays:dates where 1<dates mod 7; tradingDays:weekdays except 2020.04.10; nDays:count tradingDays; seed:-314159; system \"S \",string seed; volABC:([]sym:nDays#`ABC;date:tradingDays;dailyVolume:nDays?200000+nDays?300000); volABC:update floor dailyVolume*0.2 from volABC where date<2020.04.08; system \"S \",string seed; volDEF:([]sym:nDays#`DEF;date:tradingDays;dailyVolume:nDays?800000+nDays?300000); volDEF:update dailyVolume*10 from volDEF where date<2020.04.13; `date xasc volABC,volDEF }; events:getSplitEvents[]; volume:getDailyVolume[]; Find the 5-day Average Daily Volume (ADV) before and after the split event. Answer \u00b6 Below is the suggested answer: / Find the distinct trading days and sort them in ascending order tradingDays:`date xasc select distinct date from volume; / Find the start date and end date of the 10 trading days around each date / Note that the end date is calculated as current date plus 4 / One implicit assumption is here the tradingDays table is continuous, i.e. / no missing trading day in this table. tradingDays:update startDate:date i-5,endDate:date i+4 from tradingDays; / Join the start/end date with the effective date of the stock split so / that for each effective date, we know the stop date it need to look / backward and forward. events:events lj `date xkey tradingDays; / Join the target data period and effective date with volume data volume:volume lj `sym xkey select sym,effectiveDate:date,startDate,endDate from events; / Keep only volume data within the target data period volume:select from volume where date within (startDate;endDate); / Label each day as before or after the split effective date volume:update label:?[date<effectiveDate;`Before;`After] from volume; / Calculate the average volume by symbol and whether it is before or after the split select adv:avg dailyVolume by sym,label from volume","title":"2020.04.27"},{"location":"2020/2020.04.27/#introduction","text":"To gauge the effect of an event on market measures like volume and volatility, one simple way is to compare the measures before and after the event. To make a fair comparison, it makes sense to use the same number of trading days in the before and after data sample periods. One of such events is stock split or reverse split. The most common split ratios are 2-for-1, which means that the stockholder will have two for every share held earlier. Reverse stock splits are the opposite transaction, where a company divides, instead of multiplies, the number of shares that stockholders own, raising the market price accordingly. Three key pieces of information about a stock split is: symbol: the trading identifier of the stock date: the effective date of the split split ratio: how many new shares one existing share is converted to","title":"Introduction"},{"location":"2020/2020.04.27/#question","text":"The function getSplitEvents simulates the stock split events which contain the trading identifier ( sym ), effective date ( date ) and the split ratio ( splitRatio ). The function getDailyVolume simulates the daily volume around the stock split effective date. getSplitEvents:{ ([]sym:`ABC`DEF;date:2020.04.08 2020.04.13;splitRatio:0.2 10) }; getDailyVolume:{ dates:2020.03.10+til 50; weekdays:dates where 1<dates mod 7; tradingDays:weekdays except 2020.04.10; nDays:count tradingDays; seed:-314159; system \"S \",string seed; volABC:([]sym:nDays#`ABC;date:tradingDays;dailyVolume:nDays?200000+nDays?300000); volABC:update floor dailyVolume*0.2 from volABC where date<2020.04.08; system \"S \",string seed; volDEF:([]sym:nDays#`DEF;date:tradingDays;dailyVolume:nDays?800000+nDays?300000); volDEF:update dailyVolume*10 from volDEF where date<2020.04.13; `date xasc volABC,volDEF }; events:getSplitEvents[]; volume:getDailyVolume[]; Find the 5-day Average Daily Volume (ADV) before and after the split event.","title":"Question"},{"location":"2020/2020.04.27/#answer","text":"Below is the suggested answer: / Find the distinct trading days and sort them in ascending order tradingDays:`date xasc select distinct date from volume; / Find the start date and end date of the 10 trading days around each date / Note that the end date is calculated as current date plus 4 / One implicit assumption is here the tradingDays table is continuous, i.e. / no missing trading day in this table. tradingDays:update startDate:date i-5,endDate:date i+4 from tradingDays; / Join the start/end date with the effective date of the stock split so / that for each effective date, we know the stop date it need to look / backward and forward. events:events lj `date xkey tradingDays; / Join the target data period and effective date with volume data volume:volume lj `sym xkey select sym,effectiveDate:date,startDate,endDate from events; / Keep only volume data within the target data period volume:select from volume where date within (startDate;endDate); / Label each day as before or after the split effective date volume:update label:?[date<effectiveDate;`Before;`After] from volume; / Calculate the average volume by symbol and whether it is before or after the split select adv:avg dailyVolume by sym,label from volume","title":"Answer"},{"location":"2020/2020.04.27a/","text":"Answer \u00b6 Below is the suggested answer: / Find the distinct trading days and sort them in ascending order tradingDays:`date xasc select distinct date from volume; / Find the start date and end date of the 10 trading days around each date / Note that the end date is calculated as current date plus 4 / One implicit assumption is here the tradingDays table is continuous, i.e. / no missing trading day in this table. tradingDays:update startDate:date i-5,endDate:date i+4 from tradingDays; / Join the start/end date with the effective date of the stock split so / that for each effective date, we know the stop date it need to look / backward and forward. events:events lj `date xkey tradingDays; / Join the target data period and effective date with volume data volume:volume lj `sym xkey select sym,effectiveDate:date,startDate,endDate from events; / Keep only volume data within the target data period volume:select from volume where date within (startDate;endDate); / Label each day as before or after the split effective date volume:update label:?[date<effectiveDate;`Before;`After] from volume; / Calculate the average volume by symbol and whether it is before or after the split select adv:avg dailyVolume by sym,label from volume","title":"2020.04.27a"},{"location":"2020/2020.04.27a/#answer","text":"Below is the suggested answer: / Find the distinct trading days and sort them in ascending order tradingDays:`date xasc select distinct date from volume; / Find the start date and end date of the 10 trading days around each date / Note that the end date is calculated as current date plus 4 / One implicit assumption is here the tradingDays table is continuous, i.e. / no missing trading day in this table. tradingDays:update startDate:date i-5,endDate:date i+4 from tradingDays; / Join the start/end date with the effective date of the stock split so / that for each effective date, we know the stop date it need to look / backward and forward. events:events lj `date xkey tradingDays; / Join the target data period and effective date with volume data volume:volume lj `sym xkey select sym,effectiveDate:date,startDate,endDate from events; / Keep only volume data within the target data period volume:select from volume where date within (startDate;endDate); / Label each day as before or after the split effective date volume:update label:?[date<effectiveDate;`Before;`After] from volume; / Calculate the average volume by symbol and whether it is before or after the split select adv:avg dailyVolume by sym,label from volume","title":"Answer"},{"location":"2020/2020.04.27q/","text":"Source: adopted from here Introduction \u00b6 To gauge the effect of an event on market measures like volume and volatility, one simple way is to compare the measures before and after the event. To make a fair comparison, it makes sense to use the same number of trading days in the before and after data sample periods. One of such events is stock split or reverse split. The most common split ratios are 2-for-1, which means that the stockholder will have two for every share held earlier. Reverse stock splits are the opposite transaction, where a company divides, instead of multiplies, the number of shares that stockholders own, raising the market price accordingly. Three key pieces of information about a stock split is: symbol: the trading identifier of the stock date: the effective date of the split split ratio: how many new shares one existing share is converted to Question \u00b6 The function getSplitEvents simulates the stock split events which contain the trading identifier ( sym ), effective date ( date ) and the split ratio ( splitRatio ). The function getDailyVolume simulates the daily volume around the stock split effective date. getSplitEvents:{ ([]sym:`ABC`DEF;date:2020.04.08 2020.04.13;splitRatio:0.2 10) }; getDailyVolume:{ dates:2020.03.10+til 50; weekdays:dates where 1<dates mod 7; tradingDays:weekdays except 2020.04.10; nDays:count tradingDays; seed:-314159; system \"S \",string seed; volABC:([]sym:nDays#`ABC;date:tradingDays;dailyVolume:nDays?200000+nDays?300000); volABC:update floor dailyVolume*0.2 from volABC where date<2020.04.08; system \"S \",string seed; volDEF:([]sym:nDays#`DEF;date:tradingDays;dailyVolume:nDays?800000+nDays?300000); volDEF:update dailyVolume*10 from volDEF where date<2020.04.13; `date xasc volABC,volDEF }; events:getSplitEvents[]; volume:getDailyVolume[]; Find the 5-day Average Daily Volume (ADV) before and after the split event.","title":"2020.04.27q"},{"location":"2020/2020.04.27q/#introduction","text":"To gauge the effect of an event on market measures like volume and volatility, one simple way is to compare the measures before and after the event. To make a fair comparison, it makes sense to use the same number of trading days in the before and after data sample periods. One of such events is stock split or reverse split. The most common split ratios are 2-for-1, which means that the stockholder will have two for every share held earlier. Reverse stock splits are the opposite transaction, where a company divides, instead of multiplies, the number of shares that stockholders own, raising the market price accordingly. Three key pieces of information about a stock split is: symbol: the trading identifier of the stock date: the effective date of the split split ratio: how many new shares one existing share is converted to","title":"Introduction"},{"location":"2020/2020.04.27q/#question","text":"The function getSplitEvents simulates the stock split events which contain the trading identifier ( sym ), effective date ( date ) and the split ratio ( splitRatio ). The function getDailyVolume simulates the daily volume around the stock split effective date. getSplitEvents:{ ([]sym:`ABC`DEF;date:2020.04.08 2020.04.13;splitRatio:0.2 10) }; getDailyVolume:{ dates:2020.03.10+til 50; weekdays:dates where 1<dates mod 7; tradingDays:weekdays except 2020.04.10; nDays:count tradingDays; seed:-314159; system \"S \",string seed; volABC:([]sym:nDays#`ABC;date:tradingDays;dailyVolume:nDays?200000+nDays?300000); volABC:update floor dailyVolume*0.2 from volABC where date<2020.04.08; system \"S \",string seed; volDEF:([]sym:nDays#`DEF;date:tradingDays;dailyVolume:nDays?800000+nDays?300000); volDEF:update dailyVolume*10 from volDEF where date<2020.04.13; `date xasc volABC,volDEF }; events:getSplitEvents[]; volume:getDailyVolume[]; Find the 5-day Average Daily Volume (ADV) before and after the split event.","title":"Question"},{"location":"2020/2020.05.04/","text":"Source: adopted from here Introduction \u00b6 The famous NYSE TAQ data provides trades and quotes on a T+1 basis. Every algorithmic trading quant in U.S. equities should be familiar with this data set. NYSE also provides data specifications and some sample data so that unsubscribed users can get a flavor of what the data offers. This data is also available to students if your school offers access to Wharton Business School Dataset . Thanks to the advocate of data transparency by FINRA, more and more information about dark pools in the United States is disclosed over the last five years. Some data on ATS and non-ATS is release here . FINRA releases weekly aggregated ATS and non-ATS data by symbol and venue. This provides a historical liquidity distribution among all off-market trading venues. All the off-market trades are reported to SIP (Securities Information Processor), which is the data source for NYSE TAQ. In SIP, all off-market trades are marked with exchange D . Question \u00b6 From NYSE TAQ data, we can classify each off-market trade as one of the following three categories: AboveMidQuote AtMidQuote BelowMidQuote For a given stock ABCD , it is assumed that the distribution of volume among the three price levels are shown in table proportionByPriceLevel , and the volume traded on each venues are given in table atsVolume . For simplicity, only 3 ATS venues are included in this question. portions:([] priceLevel:`AboveMidQuote`AtMidQuote`BelowMidQuote; portion:0.2 0.5 0.3 ); atsVolume:([] venue:`CROS`JPMX`MSPL; qty:384818 130987 177100 ); Let's assume the volume traded on each venue follows the same distribution dictated by proportionByPriceLevel . Find the volume traded at each price level for each venue. The resulting table should have three columns and 9 rows. Your output should look like this: venue priceLevel qtyAtPriceLevel CROS AboveMidQuote 76963.6 CROS AtMidQuote 192409 CROS BelowMidQuote 115445.4 JPMX AboveMidQuote 26197.4 JPMX AtMidQuote 65493.5 JPMX BelowMidQuote 39296.1 MSPL AboveMidQuote 35420 MSPL AtMidQuote 88550 MSPL BelowMidQuote 53130","title":"2020.05.04"},{"location":"2020/2020.05.04/#introduction","text":"The famous NYSE TAQ data provides trades and quotes on a T+1 basis. Every algorithmic trading quant in U.S. equities should be familiar with this data set. NYSE also provides data specifications and some sample data so that unsubscribed users can get a flavor of what the data offers. This data is also available to students if your school offers access to Wharton Business School Dataset . Thanks to the advocate of data transparency by FINRA, more and more information about dark pools in the United States is disclosed over the last five years. Some data on ATS and non-ATS is release here . FINRA releases weekly aggregated ATS and non-ATS data by symbol and venue. This provides a historical liquidity distribution among all off-market trading venues. All the off-market trades are reported to SIP (Securities Information Processor), which is the data source for NYSE TAQ. In SIP, all off-market trades are marked with exchange D .","title":"Introduction"},{"location":"2020/2020.05.04/#question","text":"From NYSE TAQ data, we can classify each off-market trade as one of the following three categories: AboveMidQuote AtMidQuote BelowMidQuote For a given stock ABCD , it is assumed that the distribution of volume among the three price levels are shown in table proportionByPriceLevel , and the volume traded on each venues are given in table atsVolume . For simplicity, only 3 ATS venues are included in this question. portions:([] priceLevel:`AboveMidQuote`AtMidQuote`BelowMidQuote; portion:0.2 0.5 0.3 ); atsVolume:([] venue:`CROS`JPMX`MSPL; qty:384818 130987 177100 ); Let's assume the volume traded on each venue follows the same distribution dictated by proportionByPriceLevel . Find the volume traded at each price level for each venue. The resulting table should have three columns and 9 rows. Your output should look like this: venue priceLevel qtyAtPriceLevel CROS AboveMidQuote 76963.6 CROS AtMidQuote 192409 CROS BelowMidQuote 115445.4 JPMX AboveMidQuote 26197.4 JPMX AtMidQuote 65493.5 JPMX BelowMidQuote 39296.1 MSPL AboveMidQuote 35420 MSPL AtMidQuote 88550 MSPL BelowMidQuote 53130","title":"Question"},{"location":"2020/2020.05.04a/","text":"Answer \u00b6 Below is the suggested answer: / Find all distinct price levels as a list priceLevels:exec distinct priceLevel from portions; / Update with a new column for price level. / Please note that each cell value is a list by itself. volume:update priceLevel:count[atsVolume]#enlist priceLevels from atsVolume; / Use ungroup to expand the table volume:ungroup volume; / Join market portion for each price level with ATS volume volume:volume lj `priceLevel xkey portions; / Calculate the volume at each price level for each venue volume:update qtyAtPriceLevel:qty*portion from volume; / Select final columns you want to keep select venue,priceLevel,qtyAtPriceLevel from volume","title":"2020.05.04a"},{"location":"2020/2020.05.04a/#answer","text":"Below is the suggested answer: / Find all distinct price levels as a list priceLevels:exec distinct priceLevel from portions; / Update with a new column for price level. / Please note that each cell value is a list by itself. volume:update priceLevel:count[atsVolume]#enlist priceLevels from atsVolume; / Use ungroup to expand the table volume:ungroup volume; / Join market portion for each price level with ATS volume volume:volume lj `priceLevel xkey portions; / Calculate the volume at each price level for each venue volume:update qtyAtPriceLevel:qty*portion from volume; / Select final columns you want to keep select venue,priceLevel,qtyAtPriceLevel from volume","title":"Answer"},{"location":"2020/2020.05.04q/","text":"Source: adopted from here Introduction \u00b6 The famous NYSE TAQ data provides trades and quotes on a T+1 basis. Every algorithmic trading quant in U.S. equities should be familiar with this data set. NYSE also provides data specifications and some sample data so that unsubscribed users can get a flavor of what the data offers. This data is also available to students if your school offers access to Wharton Business School Dataset . Thanks to the advocate of data transparency by FINRA, more and more information about dark pools in the United States is disclosed over the last five years. Some data on ATS and non-ATS is release here . FINRA releases weekly aggregated ATS and non-ATS data by symbol and venue. This provides a historical liquidity distribution among all off-market trading venues. All the off-market trades are reported to SIP (Securities Information Processor), which is the data source for NYSE TAQ. In SIP, all off-market trades are marked with exchange D . Question \u00b6 From NYSE TAQ data, we can classify each off-market trade as one of the following three categories: AboveMidQuote AtMidQuote BelowMidQuote For a given stock ABCD , it is assumed that the distribution of volume among the three price levels are shown in table proportionByPriceLevel , and the volume traded on each venues are given in table atsVolume . For simplicity, only 3 ATS venues are included in this question. portions:([] priceLevel:`AboveMidQuote`AtMidQuote`BelowMidQuote; portion:0.2 0.5 0.3 ); atsVolume:([] venue:`CROS`JPMX`MSPL; qty:384818 130987 177100 ); Let's assume the volume traded on each venue follows the same distribution dictated by proportionByPriceLevel . Find the volume traded at each price level for each venue. The resulting table should have three columns and 9 rows. Your output should look like this: venue priceLevel qtyAtPriceLevel CROS AboveMidQuote 76963.6 CROS AtMidQuote 192409 CROS BelowMidQuote 115445.4 JPMX AboveMidQuote 26197.4 JPMX AtMidQuote 65493.5 JPMX BelowMidQuote 39296.1 MSPL AboveMidQuote 35420 MSPL AtMidQuote 88550 MSPL BelowMidQuote 53130","title":"2020.05.04q"},{"location":"2020/2020.05.04q/#introduction","text":"The famous NYSE TAQ data provides trades and quotes on a T+1 basis. Every algorithmic trading quant in U.S. equities should be familiar with this data set. NYSE also provides data specifications and some sample data so that unsubscribed users can get a flavor of what the data offers. This data is also available to students if your school offers access to Wharton Business School Dataset . Thanks to the advocate of data transparency by FINRA, more and more information about dark pools in the United States is disclosed over the last five years. Some data on ATS and non-ATS is release here . FINRA releases weekly aggregated ATS and non-ATS data by symbol and venue. This provides a historical liquidity distribution among all off-market trading venues. All the off-market trades are reported to SIP (Securities Information Processor), which is the data source for NYSE TAQ. In SIP, all off-market trades are marked with exchange D .","title":"Introduction"},{"location":"2020/2020.05.04q/#question","text":"From NYSE TAQ data, we can classify each off-market trade as one of the following three categories: AboveMidQuote AtMidQuote BelowMidQuote For a given stock ABCD , it is assumed that the distribution of volume among the three price levels are shown in table proportionByPriceLevel , and the volume traded on each venues are given in table atsVolume . For simplicity, only 3 ATS venues are included in this question. portions:([] priceLevel:`AboveMidQuote`AtMidQuote`BelowMidQuote; portion:0.2 0.5 0.3 ); atsVolume:([] venue:`CROS`JPMX`MSPL; qty:384818 130987 177100 ); Let's assume the volume traded on each venue follows the same distribution dictated by proportionByPriceLevel . Find the volume traded at each price level for each venue. The resulting table should have three columns and 9 rows. Your output should look like this: venue priceLevel qtyAtPriceLevel CROS AboveMidQuote 76963.6 CROS AtMidQuote 192409 CROS BelowMidQuote 115445.4 JPMX AboveMidQuote 26197.4 JPMX AtMidQuote 65493.5 JPMX BelowMidQuote 39296.1 MSPL AboveMidQuote 35420 MSPL AtMidQuote 88550 MSPL BelowMidQuote 53130","title":"Question"},{"location":"2020/2020.05.11/","text":"Source: adopted from here Introduction \u00b6 Question \u00b6 Answer \u00b6 Below is the suggested answer:","title":"2020.05.11"},{"location":"2020/2020.05.11/#introduction","text":"","title":"Introduction"},{"location":"2020/2020.05.11/#question","text":"","title":"Question"},{"location":"2020/2020.05.11/#answer","text":"Below is the suggested answer:","title":"Answer"},{"location":"2020/2020.05.11a/","text":"Answer \u00b6 Below is the suggested answer:","title":"2020.05.11a"},{"location":"2020/2020.05.11a/#answer","text":"Below is the suggested answer:","title":"Answer"},{"location":"2020/2020.05.11q/","text":"Source: adopted from here Introduction \u00b6 Question \u00b6","title":"2020.05.11q"},{"location":"2020/2020.05.11q/#introduction","text":"","title":"Introduction"},{"location":"2020/2020.05.11q/#question","text":"","title":"Question"}]}